[
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "cerebras.cloud.sdk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "AsyncCerebras",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "DefaultAioHttpClient",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "importPath": "aiservices.chat.implementations",
        "description": "aiservices.chat.implementations",
        "isExtraImport": true,
        "detail": "aiservices.chat.implementations",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices.chat.workers",
        "description": "aiservices.chat.workers",
        "isExtraImport": true,
        "detail": "aiservices.chat.workers",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponse",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "asyncpg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncpg",
        "description": "asyncpg",
        "detail": "asyncpg",
        "documentation": {}
    },
    {
        "label": "register_vector",
        "importPath": "pgvector.asyncpg",
        "description": "pgvector.asyncpg",
        "isExtraImport": true,
        "detail": "pgvector.asyncpg",
        "documentation": {}
    },
    {
        "label": "GetGraphFromDocResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "CHunkTextsModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "GetGraphFromDocResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkMatchedNodeModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkImagesModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkSectionModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "BuildGraphFromDocServiceImpl_Rag",
        "importPath": "ragservices.implementations",
        "description": "ragservices.implementations",
        "isExtraImport": true,
        "detail": "ragservices.implementations",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDoc_Rag",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag",
        "importPath": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "isExtraImport": true,
        "detail": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractImageIndexFromChunkSystemPrompt_Rag",
        "importPath": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "isExtraImport": true,
        "detail": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "firebase_admin",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "credentials",
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "isExtraImport": true,
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "storage",
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "isExtraImport": true,
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "importPath": "dbservices",
        "description": "dbservices",
        "isExtraImport": true,
        "detail": "dbservices",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "importPath": "dbservices",
        "description": "dbservices",
        "isExtraImport": true,
        "detail": "dbservices",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocService_Server",
        "importPath": "server.services",
        "description": "server.services",
        "isExtraImport": true,
        "detail": "server.services",
        "documentation": {}
    },
    {
        "label": "ChatService_Server",
        "importPath": "server.services",
        "description": "server.services",
        "isExtraImport": true,
        "detail": "server.services",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ResponseEnum_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocServiceImpl_Server",
        "importPath": "server.serviceimplementations",
        "description": "server.serviceimplementations",
        "isExtraImport": true,
        "detail": "server.serviceimplementations",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl_Server",
        "importPath": "server.serviceimplementations",
        "description": "server.serviceimplementations",
        "isExtraImport": true,
        "detail": "server.serviceimplementations",
        "documentation": {}
    },
    {
        "label": "BuildGraphFromDocService_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "GetGraphFromDocResponseModel_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "BuildGraphFromDocService_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceAbusiveUserQuerySystemPrompt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceConfidentialUserQuerySystemPrompt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQuerySystemPropt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceUserQueryLLMSystemPropt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "asynccontextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "GragDocRouter",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "ChatRouter",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "kind": 6,
        "importPath": "aiservices.chat.enums.ChatServiceEnums",
        "description": "aiservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTANT = \"assistant\"\nclass ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")",
        "detail": "aiservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "kind": 6,
        "importPath": "aiservices.chat.enums.ChatServiceEnums",
        "description": "aiservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")\n    CONFLICT = (409, \"CONFLICT\")\n    ENTITY_ERROR = (422, \"ENTITY_ERROR\")\n    RATE_LIMIT = (429, \"RATE_LIMIT\")",
        "detail": "aiservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "kind": 6,
        "importPath": "aiservices.chat.implementations.ChatServiceImplementation",
        "description": "aiservices.chat.implementations.ChatServiceImplementation",
        "peekOfCode": "class ChatServiceImpl(ABC):\n    @abstractmethod\n    async def Chat(self, modelParams: ChatServiceRequestModel) -> ChatServiceResponseModel | StreamingResponse:\n        pass\n    @abstractmethod\n    def HandleApiStatusError(\n        self, statusCode: int\n    ) -> ChatServiceResponseModel :\n        pass",
        "detail": "aiservices.chat.implementations.ChatServiceImplementation",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceMessageModel(BaseModel):\n    role: Optional[ChatServiceMessageRoleEnum] = ChatServiceMessageRoleEnum.USER\n    content: str\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []\n    additionalProperties: bool = False\nclass ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str\n    responseFormat: Optional[ChatServiceCerebrasFormatModel] = None\n    topP:float = 1.0\n    seed:int = 42",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceMessageModel(BaseModel):\n    role: ChatServiceMessageRoleEnum = ChatServiceMessageRoleEnum.ASSISTANT\n    content: str\nclass ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0\n    usage: ChatServiceUsageModel\nclass ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "kind": 6,
        "importPath": "aiservices.chat.services.ChatServices",
        "description": "aiservices.chat.services.ChatServices",
        "peekOfCode": "class ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,\n            404: ChatServiceResponseStatusEnum.NOT_FOUND,\n        }\n        message = errorCodes.get(statusCode, ChatServiceResponseStatusEnum.SERVER_ERROR)\n        return ChatServiceResponseModel(status=message)",
        "detail": "aiservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "aiservices.chat.services.ChatServices",
        "description": "aiservices.chat.services.ChatServices",
        "peekOfCode": "client = AsyncCerebras(\n    api_key=GetCerebrasApiKey(),\n    http_client=DefaultAioHttpClient(),\n)\nclass ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,",
        "detail": "aiservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "kind": 2,
        "importPath": "aiservices.chat.workers.GetApiKey",
        "description": "aiservices.chat.workers.GetApiKey",
        "peekOfCode": "def GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "aiservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "CEREBRAS_API_KEY",
        "kind": 5,
        "importPath": "aiservices.chat.workers.GetApiKey",
        "description": "aiservices.chat.workers.GetApiKey",
        "peekOfCode": "CEREBRAS_API_KEY = cast(Any, os.getenv(\"CEREBRAS_API_KEY\"))\ndef GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "aiservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.ChatEnums",
        "description": "aiservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTENT = \"assistant\"\nclass MistralChatResponseStatusEnum(Enum):\n    ERROR = (200, \"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")",
        "detail": "aiservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.ChatEnums",
        "description": "aiservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatResponseStatusEnum(Enum):\n    ERROR = (200, \"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")",
        "detail": "aiservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.EmbeddingEnums",
        "description": "aiservices.embedding.enums.EmbeddingEnums",
        "peekOfCode": "class EmbeddingResponseEnum(Enum):\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    ERROR = (200, \"ERROR\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")",
        "detail": "aiservices.embedding.enums.EmbeddingEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "description": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "peekOfCode": "class EmbeddingServiceImpl(ABC):\n    @abstractmethod\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        pass\n    @abstractmethod\n    def FindSimilarity(self, vec1: list[float], vec2: list[float]) -> float:\n        pass",
        "detail": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.MistralChatImpl",
        "description": "aiservices.embedding.implementations.MistralChatImpl",
        "peekOfCode": "class MistralChatImpl(ABC):\n    @abstractmethod\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        pass",
        "detail": "aiservices.embedding.implementations.MistralChatImpl",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.RerankingImplementation",
        "description": "aiservices.embedding.implementations.RerankingImplementation",
        "peekOfCode": "class RerankingImpl(ABC):\n    @abstractmethod\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        pass\n    @abstractmethod\n    def FindTopKResultsFromVectors(self,request:FindTopKresultsFromVectorsRequestModel) -> FindTopKresultsFromVectorsResponseModel:\n        pass",
        "detail": "aiservices.embedding.implementations.RerankingImplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestMessageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestMessageModel(BaseModel):\n    role: MistralChatMessageRoleEnum = MistralChatMessageRoleEnum.USER\n    content: str | list[str]\nclass MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None\nclass MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int\n    totalTokens: int\nclass MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingUsageModel(BaseModel):\n    promptTokens: int | None\n    completionTokens: int | None\n    totalTokens: int | None\nclass EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None\n    data: list[EmbeddingDataModel] | None = None",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingRequestModel(BaseModel):\n    model: str = \"jina-reranker-m0\"\n    query: str\n    docs: list[str]\n    topN: int = 5\n    returnDocuments: bool = False\nclass RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.EmbeddingService",
        "description": "aiservices.embedding.services.EmbeddingService",
        "peekOfCode": "class EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(\n                    embedding=obj.embedding,",
        "detail": "aiservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "mistralClient",
        "kind": 5,
        "importPath": "aiservices.embedding.services.EmbeddingService",
        "description": "aiservices.embedding.services.EmbeddingService",
        "peekOfCode": "mistralClient = Mistral(api_key=GetMistralApiKey())\nclass EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(",
        "detail": "aiservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "MistralChatService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.MistralChatService",
        "description": "aiservices.embedding.services.MistralChatService",
        "peekOfCode": "class MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}\n                )",
        "detail": "aiservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "mistral",
        "kind": 5,
        "importPath": "aiservices.embedding.services.MistralChatService",
        "description": "aiservices.embedding.services.MistralChatService",
        "peekOfCode": "mistral = Mistral(api_key=GetMistralApiKey())\nclass MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}",
        "detail": "aiservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.RerankingService",
        "description": "aiservices.embedding.services.RerankingService",
        "peekOfCode": "class RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        try:\n            data: Any = {\n                \"model\": modelParams.model,\n                \"query\": modelParams.query,\n                \"documents\": modelParams.docs,\n                \"top_n\": modelParams.topN,",
        "detail": "aiservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "jinaClient",
        "kind": 5,
        "importPath": "aiservices.embedding.services.RerankingService",
        "description": "aiservices.embedding.services.RerankingService",
        "peekOfCode": "jinaClient = requests.Session()\njinaClient.headers.update(\n    {\n        \"Authorization\": f\"Bearer {GetJinaApiKey()}\",\n        \"Content-Type\": \"application/json\",\n    }\n)\nclass RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel",
        "detail": "aiservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "kind": 2,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "kind": 2,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MISTRAL_API_KEY",
        "kind": 5,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "MISTRAL_API_KEY = cast(Any, os.getenv(\"MISTRAL_API_KEY\"))\nJINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "JINA_API_KEY",
        "kind": 5,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "JINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "kind": 6,
        "importPath": "dbservices.PsqlDb",
        "description": "dbservices.PsqlDb",
        "peekOfCode": "class PsqlDb:\n    def __init__(self, db_url: str):\n        self.db_url: str = db_url\n        self.pool: Any = None\n    async def connect(self) -> None:\n        async def _init(conn):\n            # enable the extension if not already\n            await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n            # register pgvector type with asyncpg\n            await register_vector(conn)",
        "detail": "dbservices.PsqlDb",
        "documentation": {}
    },
    {
        "label": "BuildGraphFromDocServiceImpl_Rag",
        "kind": 6,
        "importPath": "ragservices.implementations.BuildGraphFromDocServiceImpl_Rag",
        "description": "ragservices.implementations.BuildGraphFromDocServiceImpl_Rag",
        "peekOfCode": "class BuildGraphFromDocServiceImpl_Rag(ABC):\n    @abstractmethod\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        pass\n    @abstractmethod\n    async def UploadImagesFromDocToFirebase_Rag(\n        self, base64Str: str, folder: str\n    ) -> str:",
        "detail": "ragservices.implementations.BuildGraphFromDocServiceImpl_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkMatchedNodeModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ChunkMatchedNodeModel_Rag(BaseModel):\n    score: float\n    chunkId: UUID\nclass ChunkImagesModel_Rag(BaseModel):\n    image: str\n    description: str\nclass CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkImagesModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ChunkImagesModel_Rag(BaseModel):\n    image: str\n    description: str\nclass CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    entities: list[str]\n    questions: list[str]\n    questionVectors: list[list[float]] | None = []",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "CHunkTextsModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    entities: list[str]\n    questions: list[str]\n    questionVectors: list[list[float]] | None = []\n    matchedNodes: list[ChunkMatchedNodeModel_Rag] | None = None\n    images: list[ChunkImagesModel_Rag] | None = None\nclass ChunkRelationModel_Rag(BaseModel):",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ChunkRelationModel_Rag(BaseModel):\n    id: UUID\n    realtion: str\n    realtionEntites: list[str]\n    relationVector: list[float] | None = None\nclass ChunkRelationsModel_Rag(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel_Rag]\nclass GetGraphFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ChunkRelationsModel_Rag(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel_Rag]\nclass GetGraphFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]\n    chunkRelations: list[ChunkRelationsModel_Rag]\nclass ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    entities: list[str]\n    realtions: list[str]\n    questions: list[str]",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "GetGraphFromDocResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class GetGraphFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]\n    chunkRelations: list[ChunkRelationsModel_Rag]\nclass ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    entities: list[str]\n    realtions: list[str]\n    questions: list[str]\n    chunk: str\n    relationshipsEntities: list[list[str]]\nclass ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    entities: list[str]\n    realtions: list[str]\n    questions: list[str]\n    chunk: str\n    relationshipsEntities: list[list[str]]\nclass ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):\n    imageindex: int | None\n    description: str\nclass ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkSectionModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):\n    imageindex: int | None\n    description: str\nclass ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):\n    sections: list[ExatrctImageIndexFromChunkSectionModel_Rag]",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildGraphFromDocModels_Rag",
        "description": "ragservices.models.BuildGraphFromDocModels_Rag",
        "peekOfCode": "class ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):\n    sections: list[ExatrctImageIndexFromChunkSectionModel_Rag]",
        "detail": "ragservices.models.BuildGraphFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "BuildGraphFromDocService_Rag",
        "kind": 6,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "class BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")\n        _HYPHEN_BREAK_RE = re.compile(r\"(\\w)-\\n(\\w)\")\n        _MULTI_NL_RE = re.compile(r\"\\n{3,}\")",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "chatService",
        "kind": 5,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "chatService = ChatService()\nembeddingService = EmbeddingService()\nrerankingService = RerankingService()\ncred = credentials.Certificate(\"./others/firebaseCred.json\")\ncast(Any, firebase_admin).initialize_app(\n    cred, {\"storageBucket\": \"testproject-b1efd.appspot.com\"}\n)\nRetryLoopIndexLimit = 3\nclass BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "embeddingService = EmbeddingService()\nrerankingService = RerankingService()\ncred = credentials.Certificate(\"./others/firebaseCred.json\")\ncast(Any, firebase_admin).initialize_app(\n    cred, {\"storageBucket\": \"testproject-b1efd.appspot.com\"}\n)\nRetryLoopIndexLimit = 3\nclass BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "rerankingService",
        "kind": 5,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "rerankingService = RerankingService()\ncred = credentials.Certificate(\"./others/firebaseCred.json\")\ncast(Any, firebase_admin).initialize_app(\n    cred, {\"storageBucket\": \"testproject-b1efd.appspot.com\"}\n)\nRetryLoopIndexLimit = 3\nclass BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "cred",
        "kind": 5,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "cred = credentials.Certificate(\"./others/firebaseCred.json\")\ncast(Any, firebase_admin).initialize_app(\n    cred, {\"storageBucket\": \"testproject-b1efd.appspot.com\"}\n)\nRetryLoopIndexLimit = 3\nclass BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "RetryLoopIndexLimit",
        "kind": 5,
        "importPath": "ragservices.services.BuildGraphFromDocService_Rag",
        "description": "ragservices.services.BuildGraphFromDocService_Rag",
        "peekOfCode": "RetryLoopIndexLimit = 3\nclass BuildGraphFromDocService_Rag(BuildGraphFromDocServiceImpl_Rag):\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")\n        _HYPHEN_BREAK_RE = re.compile(r\"(\\w)-\\n(\\w)\")",
        "detail": "ragservices.services.BuildGraphFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag",
        "kind": 5,
        "importPath": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "peekOfCode": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag = r\"\"\"\nTASK\nReturn ONLY valid JSON per the schema for ONE input chunk.\nINPUT\n{ \"chunk\": \"...\" }\nOUTPUT (conceptual)\n{\n  \"response\": {\n    \"entities\": [\"...\"],\n    \"relations\": [\"...\"],",
        "detail": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractImageIndexFromChunkSystemPrompt_Rag",
        "kind": 5,
        "importPath": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "peekOfCode": "ExtractImageIndexFromChunkSystemPrompt_Rag = r\"\"\"\nTASK\nReturn ONLY valid JSON per the schema for ONE input chunk.\nINPUT\n{ \"chunk\": \"...\" }\nOUTPUT (conceptual)\n{\n  \"response\": {\n    \"sections\": [\n      { \"imageindex\": \"7\", \"description\": \"One clear sentence (825 words) explaining why/how the image is used.\" }",
        "detail": "ragservices.utils.BuildGraphFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "GragDocRouter",
        "kind": 5,
        "importPath": "server.controllers.BuildGraphRagFromDocController_Server",
        "description": "server.controllers.BuildGraphRagFromDocController_Server",
        "peekOfCode": "GragDocRouter = APIRouter()\nBuildGraphRagFromDocServiceServer = BuildGraphRagFromDocService_Server()\nasync def GetDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@GragDocRouter.get(\"/bgrfd\")\nasync def BuildGraphFromDoc():\n    return await BuildGraphRagFromDocServiceServer.BuildGraphFromDoc(\n        \"./others/opd_manual.pdf\", await GetDb()\n    )",
        "detail": "server.controllers.BuildGraphRagFromDocController_Server",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocServiceServer",
        "kind": 5,
        "importPath": "server.controllers.BuildGraphRagFromDocController_Server",
        "description": "server.controllers.BuildGraphRagFromDocController_Server",
        "peekOfCode": "BuildGraphRagFromDocServiceServer = BuildGraphRagFromDocService_Server()\nasync def GetDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@GragDocRouter.get(\"/bgrfd\")\nasync def BuildGraphFromDoc():\n    return await BuildGraphRagFromDocServiceServer.BuildGraphFromDoc(\n        \"./others/opd_manual.pdf\", await GetDb()\n    )",
        "detail": "server.controllers.BuildGraphRagFromDocController_Server",
        "documentation": {}
    },
    {
        "label": "ChatRouter",
        "kind": 5,
        "importPath": "server.controllers.ChatController_Server",
        "description": "server.controllers.ChatController_Server",
        "peekOfCode": "ChatRouter = APIRouter()\nChatServiceServer = ChatService_Server()\n@ChatRouter.post(\"/chat/public\")\nasync def HandlePublicChat(request: ChatServiceRequestModel_Server):\n    response = await ChatServiceServer.ChatService_Server(request=request)\n    return response",
        "detail": "server.controllers.ChatController_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceServer",
        "kind": 5,
        "importPath": "server.controllers.ChatController_Server",
        "description": "server.controllers.ChatController_Server",
        "peekOfCode": "ChatServiceServer = ChatService_Server()\n@ChatRouter.post(\"/chat/public\")\nasync def HandlePublicChat(request: ChatServiceRequestModel_Server):\n    response = await ChatServiceServer.ChatService_Server(request=request)\n    return response",
        "detail": "server.controllers.ChatController_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "kind": 6,
        "importPath": "server.enums.ChatServiceEnums_Server",
        "description": "server.enums.ChatServiceEnums_Server",
        "peekOfCode": "class ChatServicePreProcessEnums_Server(Enum):\n    CONTACT_INFORMATION = \"CONTACT_INFO_ERROR\"\n    ABUSE_LANGUAGE  = \"ABUSE_LANG_ERROR\"\n    OK  = \"OK\"\n    ERROR  = \"ERROR\"\n    LLM = \"LLM\"\n    HMIS = \"HMIS\"\nclass ChatServicePreProcessRouteEnums_Server(Enum):\n    LLM = \"LLM\"\n    HMIS = \"HMIs\"",
        "detail": "server.enums.ChatServiceEnums_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "kind": 6,
        "importPath": "server.enums.ChatServiceEnums_Server",
        "description": "server.enums.ChatServiceEnums_Server",
        "peekOfCode": "class ChatServicePreProcessRouteEnums_Server(Enum):\n    LLM = \"LLM\"\n    HMIS = \"HMIs\"",
        "detail": "server.enums.ChatServiceEnums_Server",
        "documentation": {}
    },
    {
        "label": "ResponseEnum_Server",
        "kind": 6,
        "importPath": "server.enums.ResponseEnums_Server",
        "description": "server.enums.ResponseEnums_Server",
        "peekOfCode": "class ResponseEnum_Server(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")\n    CONFLICT = (409, \"CONFLICT\")\n    ENTITY_ERROR = (422, \"ENTITY_ERROR\")\n    RATE_LIMIT = (429, \"RATE_LIMIT\")",
        "detail": "server.enums.ResponseEnums_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServiceRequestModel_Server(BaseModel):\n    id: str | None = None\n    query: str\nclass ChatServicePreProcessUserQueryResponseModel_Server(BaseModel):\n    status: ChatServicePreProcessEnums_Server = (\n        ChatServicePreProcessEnums_Server.OK\n    )\n    route: ChatServicePreProcessRouteEnums_Server = (\n        ChatServicePreProcessRouteEnums_Server.LLM\n    )",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServicePreProcessUserQueryResponseModel_Server(BaseModel):\n    status: ChatServicePreProcessEnums_Server = (\n        ChatServicePreProcessEnums_Server.OK\n    )\n    route: ChatServicePreProcessRouteEnums_Server = (\n        ChatServicePreProcessRouteEnums_Server.LLM\n    )\nclass ChatServiceResponseModel_Server(BaseModel):\n    status: ResponseEnum_Server = ResponseEnum_Server.SUCCESS\n    content: str | None = None",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServiceResponseModel_Server(BaseModel):\n    status: ResponseEnum_Server = ResponseEnum_Server.SUCCESS\n    content: str | None = None",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocServiceImpl_Server",
        "kind": 6,
        "importPath": "server.serviceimplementations.BuildGraphRagFromDocServiceImpl_Server",
        "description": "server.serviceimplementations.BuildGraphRagFromDocServiceImpl_Server",
        "peekOfCode": "class BuildGraphRagFromDocServiceImpl_Server(ABC):\n    @abstractmethod\n    async def BuildGraphFromDoc(self, file:str,db:Any):\n        pass",
        "detail": "server.serviceimplementations.BuildGraphRagFromDocServiceImpl_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl_Server",
        "kind": 6,
        "importPath": "server.serviceimplementations.ChatServiceImpl_Server",
        "description": "server.serviceimplementations.ChatServiceImpl_Server",
        "peekOfCode": "class ChatServiceImpl_Server(ABC):\n    @abstractmethod\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        pass\n    @abstractmethod\n    async def LLMChat_Server(\n        self, messages: list[ChatServiceMessageModel]\n    ) -> StreamingResponse | None:",
        "detail": "server.serviceimplementations.ChatServiceImpl_Server",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocService_Server",
        "kind": 6,
        "importPath": "server.services.BuildGraphRagFromDocService_Server",
        "description": "server.services.BuildGraphRagFromDocService_Server",
        "peekOfCode": "class BuildGraphRagFromDocService_Server(BuildGraphRagFromDocServiceImpl_Server):\n    async def BuildGraphFromDoc(self, file: str, db: Any):\n        conn = await db.get_connection()\n        graph: GetGraphFromDocResponseModel_Rag = (\n            await BuildGraphRagFromDocService.BuildGraphFromDoc_Rag(file)\n        )\n        chunkTexts: list[Any] = []\n        chunkQuestions: list[Any] = []\n        chunkImages: list[Any] = []\n        chunkRelations: list[Any] = []",
        "detail": "server.services.BuildGraphRagFromDocService_Server",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocService",
        "kind": 5,
        "importPath": "server.services.BuildGraphRagFromDocService_Server",
        "description": "server.services.BuildGraphRagFromDocService_Server",
        "peekOfCode": "BuildGraphRagFromDocService = BuildGraphFromDocService_Rag()\nclass BuildGraphRagFromDocService_Server(BuildGraphRagFromDocServiceImpl_Server):\n    async def BuildGraphFromDoc(self, file: str, db: Any):\n        conn = await db.get_connection()\n        graph: GetGraphFromDocResponseModel_Rag = (\n            await BuildGraphRagFromDocService.BuildGraphFromDoc_Rag(file)\n        )\n        chunkTexts: list[Any] = []\n        chunkQuestions: list[Any] = []\n        chunkImages: list[Any] = []",
        "detail": "server.services.BuildGraphRagFromDocService_Server",
        "documentation": {}
    },
    {
        "label": "ChatService_Server",
        "kind": 6,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "class ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        if loopIndex > RetryLoopIndexLimit:\n            return ChatServicePreProcessUserQueryResponseModel_Server(\n                status=ChatServicePreProcessEnums_Server.ERROR\n            )\n        response = ChatServicePreProcessUserQueryResponseModel_Server(\n            status=ChatServicePreProcessEnums_Server.OK",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "getChatLLM",
        "kind": 2,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "def getChatLLM():\n    from main import ChatLLmService\n    return ChatLLmService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        if loopIndex > RetryLoopIndexLimit:\n            return ChatServicePreProcessUserQueryResponseModel_Server(\n                status=ChatServicePreProcessEnums_Server.ERROR",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "RetryLoopIndexLimit",
        "kind": 5,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "RetryLoopIndexLimit = 3\ndef getChatLLM():\n    from main import ChatLLmService\n    return ChatLLmService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        if loopIndex > RetryLoopIndexLimit:\n            return ChatServicePreProcessUserQueryResponseModel_Server(",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQuerySystemPropt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServicePreProcessUserQuerySystemPropt_Server = \"\"\"\nTASK\nReturn ONLY JSON:\n{\n  \"response\": {\n    \"error\": \"OK\" | \"ABUSE_LANG_ERROR\" | \"CONTACT_INFO_ERROR\",\n    \"route\": \"HMIS\" | \"LLM\"\n  }\n}\nRules",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceAbusiveUserQuerySystemPrompt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceAbusiveUserQuerySystemPrompt_Server = \"\"\"\nYou are a company policy enforcement assistant.\nThe user query was flagged as abusive.\nYour task: Write a short warning message to the user.\n- Clearly state their query contained abusive language.\n- Say that using abusive or offensive words violates company policy.\n- Warn that repeated abuse may lead to account suspension or blocking.\n- Make the tone professional, strict, but not insulting.\n- Each response should vary wording naturally (not the same sentence every time).\n- Output only the message text. Do NOT include JSON.",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceConfidentialUserQuerySystemPrompt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceConfidentialUserQuerySystemPrompt_Server = \"\"\"\nYou are a company policy enforcement assistant.\nThe user query was flagged for sharing confidential or contact information.\nYour task: Write a short warning message to the user.\n- Clearly state their query included sensitive or personal details (phone, email, Aadhaar, PAN, card, password, API key, etc.).\n- Say that sharing or requesting such information violates company policy and security guidelines.\n- Warn that this can risk their security and may result in account restrictions.\n- Make the tone professional, serious, but not harsh.\n- Each response should vary wording naturally.\n- Output only the message text. Do NOT include JSON.",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceUserQueryLLMSystemPropt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceUserQueryLLMSystemPropt_Server = \"\"\"\nYou are a helpful, concise assistant.\nGOAL\n- Answer the user's question directly and helpfully.\nSTYLE\n- Be clear and brief.\n- Use Markdown for formatting when it improves readability.\n- If you need to show code, use fenced code blocks.\nDO NOT\n- Do not add boilerplate or disclaimers unless safety requires it.",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ExtractTextAndImagesFromDoc",
        "kind": 2,
        "importPath": "utils.ExtarctTextFromDoc_Rag",
        "description": "utils.ExtarctTextFromDoc_Rag",
        "peekOfCode": "def ExtractTextAndImagesFromDoc(pdfPath: str) -> Tuple[str, List[str]]:\n    doc: Any = fitz.open(pdfPath)\n    imagesB64: List[str] = []\n    imageCounter: int = 1\n    finalTextParts: List[str] = []\n    for _, page in enumerate(doc, start=1):\n        blocks = page.get_text(\"dict\")[\"blocks\"]\n        pageItems: List[Tuple[str, float, str]] = []\n        for block in blocks:\n            if block[\"type\"] == 0:",
        "detail": "utils.ExtarctTextFromDoc_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDoc_Rag",
        "kind": 2,
        "importPath": "utils.ExtarctTextFromDoc_Rag",
        "description": "utils.ExtarctTextFromDoc_Rag",
        "peekOfCode": "def ExtractTextFromDoc_Rag(file: str) -> Tuple[str, List[str]]:\n    textWithImages, imagesB64 = ExtractTextAndImagesFromDoc(file)\n    return textWithImages, imagesB64",
        "detail": "utils.ExtarctTextFromDoc_Rag",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "k",
        "description": "k",
        "peekOfCode": "a = BuildGraphFromDocService_Rag()\nasync def main():\n    response = await a.BuildGraphFromDoc_Rag(\"./others/opd_manual.pdf\")\n    for i in response.chunkTexts:\n        print(i.text)\n        print(i.images)\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
        "detail": "k",
        "documentation": {}
    },
    {
        "label": "DATABASE_CONNECTION_STRING",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DATABASE_CONNECTION_STRING = os.getenv(\"DATABASE_CONNECTION_STRING\", \"\")\npsqlDb = PsqlDb(DATABASE_CONNECTION_STRING)\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    await psqlDb.connect()\n    yield\n    await psqlDb.close()\nserver = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "psqlDb = PsqlDb(DATABASE_CONNECTION_STRING)\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    await psqlDb.connect()\n    yield\n    await psqlDb.close()\nserver = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "server",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "server = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\nserver.include_router(GragDocRouter, prefix=\"/api/v1\")\nserver.include_router(ChatRouter, prefix=\"/api/v1/ask\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "ChatLLmService",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "ChatLLmService = ChatService()\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:server\", host=\"0.0.0.0\", port=8001, reload=False)",
        "detail": "main",
        "documentation": {}
    }
]