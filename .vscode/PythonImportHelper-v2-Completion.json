[
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "importPath": "aiservices.chat.models",
        "description": "aiservices.chat.models",
        "isExtraImport": true,
        "detail": "aiservices.chat.models",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "aiservices.chat.enums",
        "description": "aiservices.chat.enums",
        "isExtraImport": true,
        "detail": "aiservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "cerebras.cloud.sdk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "AsyncCerebras",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "DefaultAioHttpClient",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "importPath": "aiservices.chat.implementations",
        "description": "aiservices.chat.implementations",
        "isExtraImport": true,
        "detail": "aiservices.chat.implementations",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices.chat.workers",
        "description": "aiservices.chat.workers",
        "isExtraImport": true,
        "detail": "aiservices.chat.workers",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "aiservices.embedding.models",
        "description": "aiservices.embedding.models",
        "isExtraImport": true,
        "detail": "aiservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "aiservices.embedding.enums",
        "description": "aiservices.embedding.enums",
        "isExtraImport": true,
        "detail": "aiservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponse",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "importPath": "aiservices.embedding.implementations",
        "description": "aiservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "aiservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "importPath": "aiservices.embedding.workers",
        "description": "aiservices.embedding.workers",
        "isExtraImport": true,
        "detail": "aiservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "importPath": "dbservices",
        "description": "dbservices",
        "isExtraImport": true,
        "detail": "dbservices",
        "documentation": {}
    },
    {
        "label": "asyncpg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncpg",
        "description": "asyncpg",
        "detail": "asyncpg",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "register_vector",
        "importPath": "pgvector.asyncpg",
        "description": "pgvector.asyncpg",
        "isExtraImport": true,
        "detail": "pgvector.asyncpg",
        "documentation": {}
    },
    {
        "label": "ExtarctQuestionAndAnswersFromDocResponse_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "HandleQaRagBuildingProcessResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "GetRagFromDocResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExtarctQuestionAndAnswersFromDocResponse_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "HandleQaRagBuildingProcessResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "CHunkTextsModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "GetRagFromDocResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ChunkImagesModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkSectionModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "importPath": "ragservices.models",
        "description": "ragservices.models",
        "isExtraImport": true,
        "detail": "ragservices.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "aiservices",
        "description": "aiservices",
        "isExtraImport": true,
        "detail": "aiservices",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "BuildQaRagFromDocImpl_Rag",
        "importPath": "ragservices.implementations",
        "description": "ragservices.implementations",
        "isExtraImport": true,
        "detail": "ragservices.implementations",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocServiceImpl_Rag",
        "importPath": "ragservices.implementations",
        "description": "ragservices.implementations",
        "isExtraImport": true,
        "detail": "ragservices.implementations",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDocServiceImpl_Rag",
        "importPath": "ragservices.implementations",
        "description": "ragservices.implementations",
        "isExtraImport": true,
        "detail": "ragservices.implementations",
        "documentation": {}
    },
    {
        "label": "RagUtilServiceImpl_Rag",
        "importPath": "ragservices.implementations",
        "description": "ragservices.implementations",
        "isExtraImport": true,
        "detail": "ragservices.implementations",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDocService",
        "importPath": "ragservices.services.ExtractTextFromDocService_Rag",
        "description": "ragservices.services.ExtractTextFromDocService_Rag",
        "isExtraImport": true,
        "detail": "ragservices.services.ExtractTextFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDocService",
        "importPath": "ragservices.services.ExtractTextFromDocService_Rag",
        "description": "ragservices.services.ExtractTextFromDocService_Rag",
        "isExtraImport": true,
        "detail": "ragservices.services.ExtractTextFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag",
        "importPath": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "isExtraImport": true,
        "detail": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractImageIndexFromChunkSystemPrompt_Rag",
        "importPath": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "isExtraImport": true,
        "detail": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "RagUtilService_Rag",
        "importPath": "ragservices.services.RagUtilServcies_Rag",
        "description": "ragservices.services.RagUtilServcies_Rag",
        "isExtraImport": true,
        "detail": "ragservices.services.RagUtilServcies_Rag",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "firebase_admin",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "credentials",
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "isExtraImport": true,
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "storage",
        "importPath": "firebase_admin",
        "description": "firebase_admin",
        "isExtraImport": true,
        "detail": "firebase_admin",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocService_Server",
        "importPath": "server.services",
        "description": "server.services",
        "isExtraImport": true,
        "detail": "server.services",
        "documentation": {}
    },
    {
        "label": "ChatService_Server",
        "importPath": "server.services",
        "description": "server.services",
        "isExtraImport": true,
        "detail": "server.services",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "SearchOnDbResponseModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "SearchOnDbResponseModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "SearchOnDbImageModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "SearchOnDbResponseModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "SearchOnDbDocModel_Server",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "ResponseEnum_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "importPath": "server.enums",
        "description": "server.enums",
        "isExtraImport": true,
        "detail": "server.enums",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocServiceImpl_Server",
        "importPath": "server.serviceimplementations",
        "description": "server.serviceimplementations",
        "isExtraImport": true,
        "detail": "server.serviceimplementations",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl_Server",
        "importPath": "server.serviceimplementations",
        "description": "server.serviceimplementations",
        "isExtraImport": true,
        "detail": "server.serviceimplementations",
        "documentation": {}
    },
    {
        "label": "RagSearchServiceImpl_Server",
        "importPath": "server.serviceimplementations",
        "description": "server.serviceimplementations",
        "isExtraImport": true,
        "detail": "server.serviceimplementations",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocService_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "GetRagFromDocResponseModel_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "BuildQaRagFromDocService_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "HandleQaRagBuildingProcessResponseModel_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocService_Rag",
        "importPath": "ragservices",
        "description": "ragservices",
        "isExtraImport": true,
        "detail": "ragservices",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "importPath": "config.PsqlDbConfig",
        "description": "config.PsqlDbConfig",
        "isExtraImport": true,
        "detail": "config.PsqlDbConfig",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "importPath": "config.PsqlDbConfig",
        "description": "config.PsqlDbConfig",
        "isExtraImport": true,
        "detail": "config.PsqlDbConfig",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "importPath": "config.PsqlDbConfig",
        "description": "config.PsqlDbConfig",
        "isExtraImport": true,
        "detail": "config.PsqlDbConfig",
        "documentation": {}
    },
    {
        "label": "RagSearchService_Server",
        "importPath": "server.services.RagSearchService_Server",
        "description": "server.services.RagSearchService_Server",
        "isExtraImport": true,
        "detail": "server.services.RagSearchService_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceAbusiveUserQuerySystemPrompt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceConfidentialUserQuerySystemPrompt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQuerySystemPropt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceUserQueryLLMSystemPropt_Server",
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "isExtraImport": true,
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "asynccontextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "GragDocRouter",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "ChatRouter",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "kind": 6,
        "importPath": "aiservices.chat.enums.ChatServiceEnums",
        "description": "aiservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTANT = \"assistant\"\nclass ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")",
        "detail": "aiservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "kind": 6,
        "importPath": "aiservices.chat.enums.ChatServiceEnums",
        "description": "aiservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")\n    CONFLICT = (409, \"CONFLICT\")\n    ENTITY_ERROR = (422, \"ENTITY_ERROR\")\n    RATE_LIMIT = (429, \"RATE_LIMIT\")",
        "detail": "aiservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "kind": 6,
        "importPath": "aiservices.chat.implementations.ChatServiceImplementation",
        "description": "aiservices.chat.implementations.ChatServiceImplementation",
        "peekOfCode": "class ChatServiceImpl(ABC):\n    @abstractmethod\n    async def Chat(self, modelParams: ChatServiceRequestModel) -> ChatServiceResponseModel | StreamingResponse:\n        pass\n    @abstractmethod\n    def HandleApiStatusError(\n        self, statusCode: int\n    ) -> ChatServiceResponseModel :\n        pass",
        "detail": "aiservices.chat.implementations.ChatServiceImplementation",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceMessageModel(BaseModel):\n    role: Optional[ChatServiceMessageRoleEnum] = ChatServiceMessageRoleEnum.USER\n    content: str\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []\n    additionalProperties: bool = False\nclass ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str\n    responseFormat: Optional[ChatServiceCerebrasFormatModel] = None\n    topP:float = 1.0\n    seed:int = 42",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceMessageModel(BaseModel):\n    role: ChatServiceMessageRoleEnum = ChatServiceMessageRoleEnum.ASSISTANT\n    content: str\nclass ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0\n    usage: ChatServiceUsageModel\nclass ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "kind": 6,
        "importPath": "aiservices.chat.models.ChatServiceModels",
        "description": "aiservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "aiservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "kind": 6,
        "importPath": "aiservices.chat.services.ChatServices",
        "description": "aiservices.chat.services.ChatServices",
        "peekOfCode": "class ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,\n            404: ChatServiceResponseStatusEnum.NOT_FOUND,\n        }\n        message = errorCodes.get(statusCode, ChatServiceResponseStatusEnum.SERVER_ERROR)\n        return ChatServiceResponseModel(status=message)",
        "detail": "aiservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "aiservices.chat.services.ChatServices",
        "description": "aiservices.chat.services.ChatServices",
        "peekOfCode": "client = AsyncCerebras(\n    api_key=GetCerebrasApiKey(),\n    http_client=DefaultAioHttpClient(),\n)\nclass ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,",
        "detail": "aiservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "kind": 2,
        "importPath": "aiservices.chat.workers.GetApiKey",
        "description": "aiservices.chat.workers.GetApiKey",
        "peekOfCode": "def GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "aiservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "CEREBRAS_API_KEY",
        "kind": 5,
        "importPath": "aiservices.chat.workers.GetApiKey",
        "description": "aiservices.chat.workers.GetApiKey",
        "peekOfCode": "CEREBRAS_API_KEY = cast(Any, os.getenv(\"CEREBRAS_API_KEY\"))\ndef GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "aiservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.ChatEnums",
        "description": "aiservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTENT = \"assistant\"\nclass MistralChatResponseStatusEnum(Enum):\n    ERROR = (200, \"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")",
        "detail": "aiservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.ChatEnums",
        "description": "aiservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatResponseStatusEnum(Enum):\n    ERROR = (200, \"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")",
        "detail": "aiservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "kind": 6,
        "importPath": "aiservices.embedding.enums.EmbeddingEnums",
        "description": "aiservices.embedding.enums.EmbeddingEnums",
        "peekOfCode": "class EmbeddingResponseEnum(Enum):\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")\n    ERROR = (200, \"ERROR\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")",
        "detail": "aiservices.embedding.enums.EmbeddingEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "description": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "peekOfCode": "class EmbeddingServiceImpl(ABC):\n    @abstractmethod\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        pass\n    @abstractmethod\n    def FindSimilarity(self, vec1: list[float], vec2: list[float]) -> float:\n        pass",
        "detail": "aiservices.embedding.implementations.EmbeddingServiceimplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.MistralChatImpl",
        "description": "aiservices.embedding.implementations.MistralChatImpl",
        "peekOfCode": "class MistralChatImpl(ABC):\n    @abstractmethod\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        pass",
        "detail": "aiservices.embedding.implementations.MistralChatImpl",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "kind": 6,
        "importPath": "aiservices.embedding.implementations.RerankingImplementation",
        "description": "aiservices.embedding.implementations.RerankingImplementation",
        "peekOfCode": "class RerankingImpl(ABC):\n    @abstractmethod\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        pass\n    @abstractmethod\n    def FindTopKResultsFromVectors(self,request:FindTopKresultsFromVectorsRequestModel) -> FindTopKresultsFromVectorsResponseModel:\n        pass",
        "detail": "aiservices.embedding.implementations.RerankingImplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestMessageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestMessageModel(BaseModel):\n    role: MistralChatMessageRoleEnum = MistralChatMessageRoleEnum.USER\n    content: str | list[str]\nclass MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None\nclass MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int\n    totalTokens: int\nclass MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.ChatModels",
        "description": "aiservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "aiservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingUsageModel(BaseModel):\n    promptTokens: int | None\n    completionTokens: int | None\n    totalTokens: int | None\nclass EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.EmbeddingModels",
        "description": "aiservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None\n    data: list[EmbeddingDataModel] | None = None",
        "detail": "aiservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingRequestModel(BaseModel):\n    model: str = \"jina-reranker-m0\"\n    query: str\n    docs: list[str]\n    topN: int = 5\n    returnDocuments: bool = False\nclass RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "kind": 6,
        "importPath": "aiservices.embedding.models.RerankingModels",
        "description": "aiservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "aiservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.EmbeddingService",
        "description": "aiservices.embedding.services.EmbeddingService",
        "peekOfCode": "class EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(\n                    embedding=obj.embedding,",
        "detail": "aiservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "mistralClient",
        "kind": 5,
        "importPath": "aiservices.embedding.services.EmbeddingService",
        "description": "aiservices.embedding.services.EmbeddingService",
        "peekOfCode": "mistralClient = Mistral(api_key=GetMistralApiKey())\nclass EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(",
        "detail": "aiservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "MistralChatService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.MistralChatService",
        "description": "aiservices.embedding.services.MistralChatService",
        "peekOfCode": "class MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}\n                )",
        "detail": "aiservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "mistral",
        "kind": 5,
        "importPath": "aiservices.embedding.services.MistralChatService",
        "description": "aiservices.embedding.services.MistralChatService",
        "peekOfCode": "mistral = Mistral(api_key=GetMistralApiKey())\nclass MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}",
        "detail": "aiservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "kind": 6,
        "importPath": "aiservices.embedding.services.RerankingService",
        "description": "aiservices.embedding.services.RerankingService",
        "peekOfCode": "class RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        try:\n            data: Any = {\n                \"model\": modelParams.model,\n                \"query\": modelParams.query,\n                \"documents\": modelParams.docs,\n                \"top_n\": modelParams.topN,",
        "detail": "aiservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "jinaClient",
        "kind": 5,
        "importPath": "aiservices.embedding.services.RerankingService",
        "description": "aiservices.embedding.services.RerankingService",
        "peekOfCode": "jinaClient = requests.Session()\njinaClient.headers.update(\n    {\n        \"Authorization\": f\"Bearer {GetJinaApiKey()}\",\n        \"Content-Type\": \"application/json\",\n    }\n)\nclass RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel",
        "detail": "aiservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "kind": 2,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "kind": 2,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MISTRAL_API_KEY",
        "kind": 5,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "MISTRAL_API_KEY = cast(Any, os.getenv(\"MISTRAL_API_KEY\"))\nJINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "JINA_API_KEY",
        "kind": 5,
        "importPath": "aiservices.embedding.workers.GetApiKey",
        "description": "aiservices.embedding.workers.GetApiKey",
        "peekOfCode": "JINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTRAL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "aiservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "DATABASE_CONNECTION_STRING",
        "kind": 5,
        "importPath": "config.PsqlDbConfig",
        "description": "config.PsqlDbConfig",
        "peekOfCode": "DATABASE_CONNECTION_STRING = os.getenv(\"DATABASE_CONNECTION_STRING\", \"\")\npsqlDb = PsqlDb(DATABASE_CONNECTION_STRING)",
        "detail": "config.PsqlDbConfig",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "kind": 5,
        "importPath": "config.PsqlDbConfig",
        "description": "config.PsqlDbConfig",
        "peekOfCode": "psqlDb = PsqlDb(DATABASE_CONNECTION_STRING)",
        "detail": "config.PsqlDbConfig",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "kind": 6,
        "importPath": "dbservices.PsqlDb",
        "description": "dbservices.PsqlDb",
        "peekOfCode": "class PsqlDb:\n    def __init__(self, db_url: str):\n        self.db_url: str = db_url\n        self.pool: Any = None\n    async def connect(self) -> None:\n        async def _init(conn):\n            await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n            await register_vector(conn)\n        retries = 3\n        for i in range(retries):",
        "detail": "dbservices.PsqlDb",
        "documentation": {}
    },
    {
        "label": "BuildQaRagFromDocImpl_Rag",
        "kind": 6,
        "importPath": "ragservices.implementations.BuildQaRagFromDocServiceImpl_Rag",
        "description": "ragservices.implementations.BuildQaRagFromDocServiceImpl_Rag",
        "peekOfCode": "class BuildQaRagFromDocImpl_Rag(ABC):\n    @abstractmethod\n    def ExtarctQuesionAndAnsersFromDocText_Rag(\n        self, text: str\n    ) -> ExtarctQuestionAndAnswersFromDocResponse_Rag:\n        pass\n    @abstractmethod\n    async def ConvertTextsToVectorsFrom_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:",
        "detail": "ragservices.implementations.BuildQaRagFromDocServiceImpl_Rag",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocServiceImpl_Rag",
        "kind": 6,
        "importPath": "ragservices.implementations.BuildRagFromDocServiceImpl_Rag",
        "description": "ragservices.implementations.BuildRagFromDocServiceImpl_Rag",
        "peekOfCode": "class BuildRagFromDocServiceImpl_Rag(ABC):\n    @abstractmethod\n    async def ExtarctRelationsAndQuestionFromChunk_Rag(\n        self,\n        messages: list[ChatServiceMessageModel],\n        retryLoopIndex: int,\n    ) -> ExtarctRelationsAndQuestionFromChunkResponseModel_Rag:\n        pass\n    @abstractmethod\n    async def ConvertTextsToVectorsFromChunk_Rag(",
        "detail": "ragservices.implementations.BuildRagFromDocServiceImpl_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDocServiceImpl_Rag",
        "kind": 6,
        "importPath": "ragservices.implementations.ExtractTextFromDocServiceImpl_Rag",
        "description": "ragservices.implementations.ExtractTextFromDocServiceImpl_Rag",
        "peekOfCode": "class ExtractTextFromDocServiceImpl_Rag(ABC):\n    @abstractmethod\n    def ExtractTextAndImagesFromXlsx_Rag(self, docPath: str) -> Tuple[str, List[str]]:\n        pass\n    @abstractmethod\n    def ExtractTextAndImagesFromCsv_Rag(self, docPath: str) -> Tuple[str, List[str]]:\n        pass\n    @abstractmethod\n    def ExtractTextAndImagesFromDoc_Rag(self, docPath: str) -> Tuple[str, List[str]]:\n        pass",
        "detail": "ragservices.implementations.ExtractTextFromDocServiceImpl_Rag",
        "documentation": {}
    },
    {
        "label": "RagUtilServiceImpl_Rag",
        "kind": 6,
        "importPath": "ragservices.implementations.RagUtilServiceImpl_Rag",
        "description": "ragservices.implementations.RagUtilServiceImpl_Rag",
        "peekOfCode": "class RagUtilServiceImpl_Rag(ABC):\n    @abstractmethod\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        pass\n    @abstractmethod\n    async def UploadImagesFromDocToFirebase_Rag(\n        self, base64Str: str, folder: str\n    ) -> str:",
        "detail": "ragservices.implementations.RagUtilServiceImpl_Rag",
        "documentation": {}
    },
    {
        "label": "ExtarctQuestionAndAnswersFromDocResponse_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "description": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "peekOfCode": "class ExtarctQuestionAndAnswersFromDocResponse_Rag(BaseModel):\n    questions: list[str]\n    answers: list[str]\nclass HandleQaRagBuildingProcessResponseModel_Rag(\n    ExtarctQuestionAndAnswersFromDocResponse_Rag\n):\n    questionVectors: list[list[float]]",
        "detail": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "HandleQaRagBuildingProcessResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "description": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "peekOfCode": "class HandleQaRagBuildingProcessResponseModel_Rag(\n    ExtarctQuestionAndAnswersFromDocResponse_Rag\n):\n    questionVectors: list[list[float]]",
        "detail": "ragservices.models.BuildQaRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkMatchedNodeModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ChunkMatchedNodeModel_Rag(BaseModel):\n    score: float\n    chunkId: UUID\nclass ChunkImagesModel_Rag(BaseModel):\n    image: str\n    description: str\nclass CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkImagesModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ChunkImagesModel_Rag(BaseModel):\n    image: str\n    description: str\nclass CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    questions: list[str]\n    questionVectors: list[list[float]] | None = []\n    images: list[ChunkImagesModel_Rag] | None = None",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "CHunkTextsModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class CHunkTextsModel_Rag(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    questions: list[str]\n    questionVectors: list[list[float]] | None = []\n    images: list[ChunkImagesModel_Rag] | None = None\nclass ChunkRelationModel_Rag(BaseModel):\n    id: UUID\n    realtion: str",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ChunkRelationModel_Rag(BaseModel):\n    id: UUID\n    realtion: str\n    relationVector: list[float] | None = None\nclass ChunkRelationsModel_Rag(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel_Rag]\nclass GetRagFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]\n    chunkRelations: list[ChunkRelationsModel_Rag]",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ChunkRelationsModel_Rag(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel_Rag]\nclass GetRagFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]\n    chunkRelations: list[ChunkRelationsModel_Rag]\nclass ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    realtions: list[str]\n    questions: list[str]\n    chunk: str",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "GetRagFromDocResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class GetRagFromDocResponseModel_Rag(BaseModel):\n    chunkTexts: list[CHunkTextsModel_Rag]\n    chunkRelations: list[ChunkRelationsModel_Rag]\nclass ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    realtions: list[str]\n    questions: list[str]\n    chunk: str\nclass ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):\n    imageindex: int | None\n    description: str",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExtarctRelationsAndQuestionFromChunkResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ExtarctRelationsAndQuestionFromChunkResponseModel_Rag(BaseModel):\n    realtions: list[str]\n    questions: list[str]\n    chunk: str\nclass ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):\n    imageindex: int | None\n    description: str\nclass ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):\n    sections: list[ExatrctImageIndexFromChunkSectionModel_Rag]",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkSectionModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ExatrctImageIndexFromChunkSectionModel_Rag(BaseModel):\n    imageindex: int | None\n    description: str\nclass ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):\n    sections: list[ExatrctImageIndexFromChunkSectionModel_Rag]",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "ExatrctImageIndexFromChunkResponseModel_Rag",
        "kind": 6,
        "importPath": "ragservices.models.BuildRagFromDocModels_Rag",
        "description": "ragservices.models.BuildRagFromDocModels_Rag",
        "peekOfCode": "class ExatrctImageIndexFromChunkResponseModel_Rag(BaseModel):\n    sections: list[ExatrctImageIndexFromChunkSectionModel_Rag]",
        "detail": "ragservices.models.BuildRagFromDocModels_Rag",
        "documentation": {}
    },
    {
        "label": "BuildQaRagFromDocService_Rag",
        "kind": 6,
        "importPath": "ragservices.services.BuildQaRagFromDocService_Rag",
        "description": "ragservices.services.BuildQaRagFromDocService_Rag",
        "peekOfCode": "class BuildQaRagFromDocService_Rag(BuildQaRagFromDocImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n        self.batchLength = 50\n    def ExtarctQuesionAndAnsersFromDocText_Rag(\n        self, text: str\n    ) -> ExtarctQuestionAndAnswersFromDocResponse_Rag:\n        questionList = re.findall(r\"<<C1-START>>(.*?)<<C1-END>>\", text, re.DOTALL)\n        answersList = re.findall(r\"<<C2-START>>(.*?)<<C2-END>>\", text, re.DOTALL)\n        additionalAnswer = re.findall(r\"<<C3-START>>(.*?)<<C3-END>>\", text, re.DOTALL)",
        "detail": "ragservices.services.BuildQaRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "EmbeddingService_Rag",
        "kind": 5,
        "importPath": "ragservices.services.BuildQaRagFromDocService_Rag",
        "description": "ragservices.services.BuildQaRagFromDocService_Rag",
        "peekOfCode": "EmbeddingService_Rag = EmbeddingService()\nExtractedTextFromDocService_rag = ExtractTextFromDocService()\nclass BuildQaRagFromDocService_Rag(BuildQaRagFromDocImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n        self.batchLength = 50\n    def ExtarctQuesionAndAnsersFromDocText_Rag(\n        self, text: str\n    ) -> ExtarctQuestionAndAnswersFromDocResponse_Rag:\n        questionList = re.findall(r\"<<C1-START>>(.*?)<<C1-END>>\", text, re.DOTALL)",
        "detail": "ragservices.services.BuildQaRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractedTextFromDocService_rag",
        "kind": 5,
        "importPath": "ragservices.services.BuildQaRagFromDocService_Rag",
        "description": "ragservices.services.BuildQaRagFromDocService_Rag",
        "peekOfCode": "ExtractedTextFromDocService_rag = ExtractTextFromDocService()\nclass BuildQaRagFromDocService_Rag(BuildQaRagFromDocImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n        self.batchLength = 50\n    def ExtarctQuesionAndAnsersFromDocText_Rag(\n        self, text: str\n    ) -> ExtarctQuestionAndAnswersFromDocResponse_Rag:\n        questionList = re.findall(r\"<<C1-START>>(.*?)<<C1-END>>\", text, re.DOTALL)\n        answersList = re.findall(r\"<<C2-START>>(.*?)<<C2-END>>\", text, re.DOTALL)",
        "detail": "ragservices.services.BuildQaRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocService_Rag",
        "kind": 6,
        "importPath": "ragservices.services.BuildRagFromDocService_Rag",
        "description": "ragservices.services.BuildRagFromDocService_Rag",
        "peekOfCode": "class BuildRagFromDocService_Rag(BuildRagFromDocServiceImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n    async def ConvertTextsToVectorsFromChunk_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:\n        if retryLoopIndex > self.RetryLoopIndexLimit:\n            return EmbeddingResponseModel(status=EmbeddingResponseEnum.ERROR)\n        embeddingResponse = await embeddingService.ConvertTextToEmbedding(text=texts)\n        if embeddingResponse.data is None:",
        "detail": "ragservices.services.BuildRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "chatService",
        "kind": 5,
        "importPath": "ragservices.services.BuildRagFromDocService_Rag",
        "description": "ragservices.services.BuildRagFromDocService_Rag",
        "peekOfCode": "chatService = ChatService()\nembeddingService = EmbeddingService()\nrerankingService = RerankingService()\nRagUtilService = RagUtilService_Rag()\nclass BuildRagFromDocService_Rag(BuildRagFromDocServiceImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n    async def ConvertTextsToVectorsFromChunk_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:",
        "detail": "ragservices.services.BuildRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "ragservices.services.BuildRagFromDocService_Rag",
        "description": "ragservices.services.BuildRagFromDocService_Rag",
        "peekOfCode": "embeddingService = EmbeddingService()\nrerankingService = RerankingService()\nRagUtilService = RagUtilService_Rag()\nclass BuildRagFromDocService_Rag(BuildRagFromDocServiceImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n    async def ConvertTextsToVectorsFromChunk_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:\n        if retryLoopIndex > self.RetryLoopIndexLimit:",
        "detail": "ragservices.services.BuildRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "rerankingService",
        "kind": 5,
        "importPath": "ragservices.services.BuildRagFromDocService_Rag",
        "description": "ragservices.services.BuildRagFromDocService_Rag",
        "peekOfCode": "rerankingService = RerankingService()\nRagUtilService = RagUtilService_Rag()\nclass BuildRagFromDocService_Rag(BuildRagFromDocServiceImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n    async def ConvertTextsToVectorsFromChunk_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:\n        if retryLoopIndex > self.RetryLoopIndexLimit:\n            return EmbeddingResponseModel(status=EmbeddingResponseEnum.ERROR)",
        "detail": "ragservices.services.BuildRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "RagUtilService",
        "kind": 5,
        "importPath": "ragservices.services.BuildRagFromDocService_Rag",
        "description": "ragservices.services.BuildRagFromDocService_Rag",
        "peekOfCode": "RagUtilService = RagUtilService_Rag()\nclass BuildRagFromDocService_Rag(BuildRagFromDocServiceImpl_Rag):\n    def __init__(self):\n        self.RetryLoopIndexLimit = 3\n    async def ConvertTextsToVectorsFromChunk_Rag(\n        self, texts: list[str], retryLoopIndex: int\n    ) -> EmbeddingResponseModel:\n        if retryLoopIndex > self.RetryLoopIndexLimit:\n            return EmbeddingResponseModel(status=EmbeddingResponseEnum.ERROR)\n        embeddingResponse = await embeddingService.ConvertTextToEmbedding(text=texts)",
        "detail": "ragservices.services.BuildRagFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDocService",
        "kind": 6,
        "importPath": "ragservices.services.ExtractTextFromDocService_Rag",
        "description": "ragservices.services.ExtractTextFromDocService_Rag",
        "peekOfCode": "class ExtractTextFromDocService(ExtractTextFromDocServiceImpl_Rag):\n    def ExtractTextAndImagesFromXlsx_Rag(self, docPath: str) -> Tuple[str, List[str]]:\n        xls = pd.ExcelFile(docPath, engine=\"openpyxl\")\n        allText: list[str] = []\n        for sheetName in xls.sheet_names:\n            df = cast(Any, pd).read_excel(\n                docPath, sheet_name=sheetName, header=None, engine=\"openpyxl\"\n            )\n            for row in df.itertuples(index=False):\n                for colIndex, cell in enumerate(row, start=1):",
        "detail": "ragservices.services.ExtractTextFromDocService_Rag",
        "documentation": {}
    },
    {
        "label": "RagUtilService_Rag",
        "kind": 6,
        "importPath": "ragservices.services.RagUtilServcies_Rag",
        "description": "ragservices.services.RagUtilServcies_Rag",
        "peekOfCode": "class RagUtilService_Rag(RagUtilServiceImpl_Rag):\n    def __init__(self):\n        self.ExtarctTextFromDoc = ExtractTextFromDocService()\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")",
        "detail": "ragservices.services.RagUtilServcies_Rag",
        "documentation": {}
    },
    {
        "label": "cred",
        "kind": 5,
        "importPath": "ragservices.services.RagUtilServcies_Rag",
        "description": "ragservices.services.RagUtilServcies_Rag",
        "peekOfCode": "cred = credentials.Certificate(\"./others/firebaseCred.json\")\ncast(Any, firebase_admin).initialize_app(\n    cred, {\"storageBucket\": \"testproject-b1efd.appspot.com\"}\n)\nclass RagUtilService_Rag(RagUtilServiceImpl_Rag):\n    def __init__(self):\n        self.ExtarctTextFromDoc = ExtractTextFromDocService()\n    def ExtractChunksFromDoc_Rag(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:",
        "detail": "ragservices.services.RagUtilServcies_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag",
        "kind": 5,
        "importPath": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "peekOfCode": "ExtractRealtionsAndQuestionsFromChunkSystemPrompt_Rag = r\"\"\"\nTASK\nReturn ONLY valid JSON per the schema for ONE input chunk.\nINPUT\n{ \"chunk\": \"...\" }\nOUTPUT (conceptual)\n{\n  \"response\": {\n    \"relations\": [\"...\"],\n    \"questions\": [\"...\"],",
        "detail": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "ExtractImageIndexFromChunkSystemPrompt_Rag",
        "kind": 5,
        "importPath": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "description": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "peekOfCode": "ExtractImageIndexFromChunkSystemPrompt_Rag = r\"\"\"\nTASK\nReturn ONLY valid JSON per the schema for ONE mainchunk (with optional previouschunk and nextchunk for context).\nINPUT\n{ \"mainchunk\": \"...\", \"previouschunk\": \"...\", \"nextchunk\": \"...\" }\nOUTPUT (conceptual)\n{\n  \"response\": {\n    \"sections\": [\n      { \"imageindex\": \"7\", \"description\": \"One clear sentence (1530 words) explaining why the image is important and which content it relates to.\" }",
        "detail": "ragservices.utils.BuildRagFromDocSystemPrompts_Rag",
        "documentation": {}
    },
    {
        "label": "GragDocRouter",
        "kind": 5,
        "importPath": "server.controllers.BuildRagFromDocController_Server",
        "description": "server.controllers.BuildRagFromDocController_Server",
        "peekOfCode": "GragDocRouter = APIRouter()\nBuildRagFromDocServiceServer = BuildRagFromDocService_Server()\n@GragDocRouter.get(\"/brfd\")\nasync def BuildRagFromDoc():\n    return await BuildRagFromDocServiceServer.BuildRagFromDoc(\"./others/opd_manual.pdf\")",
        "detail": "server.controllers.BuildRagFromDocController_Server",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocServiceServer",
        "kind": 5,
        "importPath": "server.controllers.BuildRagFromDocController_Server",
        "description": "server.controllers.BuildRagFromDocController_Server",
        "peekOfCode": "BuildRagFromDocServiceServer = BuildRagFromDocService_Server()\n@GragDocRouter.get(\"/brfd\")\nasync def BuildRagFromDoc():\n    return await BuildRagFromDocServiceServer.BuildRagFromDoc(\"./others/opd_manual.pdf\")",
        "detail": "server.controllers.BuildRagFromDocController_Server",
        "documentation": {}
    },
    {
        "label": "ChatRouter",
        "kind": 5,
        "importPath": "server.controllers.ChatController_Server",
        "description": "server.controllers.ChatController_Server",
        "peekOfCode": "ChatRouter = APIRouter()\nChatServiceServer = ChatService_Server()\n@ChatRouter.post(\"/chat/public\")\nasync def HandlePublicChat(request: ChatServiceRequestModel_Server):\n    response = await ChatServiceServer.ChatService_Server(request=request)\n    return response",
        "detail": "server.controllers.ChatController_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceServer",
        "kind": 5,
        "importPath": "server.controllers.ChatController_Server",
        "description": "server.controllers.ChatController_Server",
        "peekOfCode": "ChatServiceServer = ChatService_Server()\n@ChatRouter.post(\"/chat/public\")\nasync def HandlePublicChat(request: ChatServiceRequestModel_Server):\n    response = await ChatServiceServer.ChatService_Server(request=request)\n    return response",
        "detail": "server.controllers.ChatController_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessEnums_Server",
        "kind": 6,
        "importPath": "server.enums.ChatServiceEnums_Server",
        "description": "server.enums.ChatServiceEnums_Server",
        "peekOfCode": "class ChatServicePreProcessEnums_Server(Enum):\n    CONTACT_INFORMATION = \"CONTACT_INFO_ERROR\"\n    ABUSE_LANGUAGE  = \"ABUSE_LANG_ERROR\"\n    OK  = \"OK\"\n    ERROR  = \"ERROR\"\n    LLM = \"LLM\"\n    HMIS = \"HMIS\"\nclass ChatServicePreProcessRouteEnums_Server(Enum):\n    LLM = \"LLM\"\n    HMIS = \"HMIs\"",
        "detail": "server.enums.ChatServiceEnums_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessRouteEnums_Server",
        "kind": 6,
        "importPath": "server.enums.ChatServiceEnums_Server",
        "description": "server.enums.ChatServiceEnums_Server",
        "peekOfCode": "class ChatServicePreProcessRouteEnums_Server(Enum):\n    LLM = \"LLM\"\n    HMIS = \"HMIs\"",
        "detail": "server.enums.ChatServiceEnums_Server",
        "documentation": {}
    },
    {
        "label": "ResponseEnum_Server",
        "kind": 6,
        "importPath": "server.enums.ResponseEnums_Server",
        "description": "server.enums.ResponseEnums_Server",
        "peekOfCode": "class ResponseEnum_Server(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")\n    CONFLICT = (409, \"CONFLICT\")\n    ENTITY_ERROR = (422, \"ENTITY_ERROR\")\n    RATE_LIMIT = (429, \"RATE_LIMIT\")",
        "detail": "server.enums.ResponseEnums_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServiceRequestModel_Server(BaseModel):\n    id: str | None = None\n    query: str\nclass ChatServicePreProcessUserQueryResponseModel_Server(BaseModel):\n    status: ChatServicePreProcessEnums_Server = ChatServicePreProcessEnums_Server.OK\n    route: ChatServicePreProcessRouteEnums_Server = (\n        ChatServicePreProcessRouteEnums_Server.LLM\n    )\n    cleanquery: str | None = None\nclass ChatServiceResponseModel_Server(BaseModel):",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQueryResponseModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServicePreProcessUserQueryResponseModel_Server(BaseModel):\n    status: ChatServicePreProcessEnums_Server = ChatServicePreProcessEnums_Server.OK\n    route: ChatServicePreProcessRouteEnums_Server = (\n        ChatServicePreProcessRouteEnums_Server.LLM\n    )\n    cleanquery: str | None = None\nclass ChatServiceResponseModel_Server(BaseModel):\n    status: ResponseEnum_Server = ResponseEnum_Server.SUCCESS\n    content: str | None = None",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel_Server",
        "kind": 6,
        "importPath": "server.models.ChatServiceModels_Server",
        "description": "server.models.ChatServiceModels_Server",
        "peekOfCode": "class ChatServiceResponseModel_Server(BaseModel):\n    status: ResponseEnum_Server = ResponseEnum_Server.SUCCESS\n    content: str | None = None",
        "detail": "server.models.ChatServiceModels_Server",
        "documentation": {}
    },
    {
        "label": "SearchOnDbImageModel_Server",
        "kind": 6,
        "importPath": "server.models.GraphRagSearchServiceModel_Server",
        "description": "server.models.GraphRagSearchServiceModel_Server",
        "peekOfCode": "class SearchOnDbImageModel_Server(BaseModel):\n    url: str\n    description: str\nclass SearchOnDbDocModel_Server(BaseModel):\n    matchedText: str\n    contextText: str\n    images: list[SearchOnDbImageModel_Server]\nclass SearchOnDbResponseModel(BaseModel):\n    docs: list[SearchOnDbDocModel_Server]",
        "detail": "server.models.GraphRagSearchServiceModel_Server",
        "documentation": {}
    },
    {
        "label": "SearchOnDbDocModel_Server",
        "kind": 6,
        "importPath": "server.models.GraphRagSearchServiceModel_Server",
        "description": "server.models.GraphRagSearchServiceModel_Server",
        "peekOfCode": "class SearchOnDbDocModel_Server(BaseModel):\n    matchedText: str\n    contextText: str\n    images: list[SearchOnDbImageModel_Server]\nclass SearchOnDbResponseModel(BaseModel):\n    docs: list[SearchOnDbDocModel_Server]",
        "detail": "server.models.GraphRagSearchServiceModel_Server",
        "documentation": {}
    },
    {
        "label": "SearchOnDbResponseModel",
        "kind": 6,
        "importPath": "server.models.GraphRagSearchServiceModel_Server",
        "description": "server.models.GraphRagSearchServiceModel_Server",
        "peekOfCode": "class SearchOnDbResponseModel(BaseModel):\n    docs: list[SearchOnDbDocModel_Server]",
        "detail": "server.models.GraphRagSearchServiceModel_Server",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocServiceImpl_Server",
        "kind": 6,
        "importPath": "server.serviceimplementations.BuildRagFromDocServiceImpl_Server",
        "description": "server.serviceimplementations.BuildRagFromDocServiceImpl_Server",
        "peekOfCode": "class BuildRagFromDocServiceImpl_Server(ABC):\n    @abstractmethod\n    async def BuildRagFromDoc(self, file:str):\n        pass\n    @abstractmethod\n    async def BuildQaRagFromDoc(self, file:str):\n        pass",
        "detail": "server.serviceimplementations.BuildRagFromDocServiceImpl_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl_Server",
        "kind": 6,
        "importPath": "server.serviceimplementations.ChatServiceImpl_Server",
        "description": "server.serviceimplementations.ChatServiceImpl_Server",
        "peekOfCode": "class ChatServiceImpl_Server(ABC):\n    @abstractmethod\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        pass\n    @abstractmethod\n    async def LLMChat_Server(\n        self, messages: list[ChatServiceMessageModel]\n    ) -> StreamingResponse | None:",
        "detail": "server.serviceimplementations.ChatServiceImpl_Server",
        "documentation": {}
    },
    {
        "label": "RagSearchServiceImpl_Server",
        "kind": 6,
        "importPath": "server.serviceimplementations.RagSearchServiceImpl_Server",
        "description": "server.serviceimplementations.RagSearchServiceImpl_Server",
        "peekOfCode": "class RagSearchServiceImpl_Server(ABC):\n    @abstractmethod\n    async def SearchOnDb_Server(self, query: str) -> SearchOnDbResponseModel:\n        pass",
        "detail": "server.serviceimplementations.RagSearchServiceImpl_Server",
        "documentation": {}
    },
    {
        "label": "BuildRagFromDocService_Server",
        "kind": 6,
        "importPath": "server.services.BuildRagFromDocService_Server",
        "description": "server.services.BuildRagFromDocService_Server",
        "peekOfCode": "class BuildRagFromDocService_Server(BuildRagFromDocServiceImpl_Server):\n    async def BuildQaRagFromDoc(self, file: str):\n        qa: HandleQaRagBuildingProcessResponseModel_Rag = (\n            await BuildQaRagFromDocService.HandleQaRagBuildingProcess_Rag(docPath=file)\n        )\n        questions: Any = []\n        answers: Any = []\n        for i, _ in enumerate(qa.questions):\n            answerId: UUID = uuid4()\n            answers.append((answerId, qa.answers[i]))",
        "detail": "server.services.BuildRagFromDocService_Server",
        "documentation": {}
    },
    {
        "label": "BuildGraphRagFromDocService",
        "kind": 5,
        "importPath": "server.services.BuildRagFromDocService_Server",
        "description": "server.services.BuildRagFromDocService_Server",
        "peekOfCode": "BuildGraphRagFromDocService = BuildRagFromDocService_Rag()\nBuildQaRagFromDocService = BuildQaRagFromDocService_Rag()\nclass BuildRagFromDocService_Server(BuildRagFromDocServiceImpl_Server):\n    async def BuildQaRagFromDoc(self, file: str):\n        qa: HandleQaRagBuildingProcessResponseModel_Rag = (\n            await BuildQaRagFromDocService.HandleQaRagBuildingProcess_Rag(docPath=file)\n        )\n        questions: Any = []\n        answers: Any = []\n        for i, _ in enumerate(qa.questions):",
        "detail": "server.services.BuildRagFromDocService_Server",
        "documentation": {}
    },
    {
        "label": "BuildQaRagFromDocService",
        "kind": 5,
        "importPath": "server.services.BuildRagFromDocService_Server",
        "description": "server.services.BuildRagFromDocService_Server",
        "peekOfCode": "BuildQaRagFromDocService = BuildQaRagFromDocService_Rag()\nclass BuildRagFromDocService_Server(BuildRagFromDocServiceImpl_Server):\n    async def BuildQaRagFromDoc(self, file: str):\n        qa: HandleQaRagBuildingProcessResponseModel_Rag = (\n            await BuildQaRagFromDocService.HandleQaRagBuildingProcess_Rag(docPath=file)\n        )\n        questions: Any = []\n        answers: Any = []\n        for i, _ in enumerate(qa.questions):\n            answerId: UUID = uuid4()",
        "detail": "server.services.BuildRagFromDocService_Server",
        "documentation": {}
    },
    {
        "label": "ChatService_Server",
        "kind": 6,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "class ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        if loopIndex > RetryLoopIndexLimit:\n            return ChatServicePreProcessUserQueryResponseModel_Server(\n                status=ChatServicePreProcessEnums_Server.ERROR\n            )\n        response = ChatServicePreProcessUserQueryResponseModel_Server(\n            status=ChatServicePreProcessEnums_Server.OK",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "getChatLLM",
        "kind": 2,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "def getChatLLM():\n    from main import ChatLLmService\n    return ChatLLmService\ndef getRankingService():\n    from main import RerankingService\n    return RerankingService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "getRankingService",
        "kind": 2,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "def getRankingService():\n    from main import RerankingService\n    return RerankingService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int\n    ) -> ChatServicePreProcessUserQueryResponseModel_Server:\n        if loopIndex > RetryLoopIndexLimit:\n            return ChatServicePreProcessUserQueryResponseModel_Server(\n                status=ChatServicePreProcessEnums_Server.ERROR",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "RetryLoopIndexLimit",
        "kind": 5,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "RetryLoopIndexLimit = 3\nRagSearchService = RagSearchService_Server()\ndef getChatLLM():\n    from main import ChatLLmService\n    return ChatLLmService\ndef getRankingService():\n    from main import RerankingService\n    return RerankingService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "RagSearchService",
        "kind": 5,
        "importPath": "server.services.ChatService_Server",
        "description": "server.services.ChatService_Server",
        "peekOfCode": "RagSearchService = RagSearchService_Server()\ndef getChatLLM():\n    from main import ChatLLmService\n    return ChatLLmService\ndef getRankingService():\n    from main import RerankingService\n    return RerankingService\nclass ChatService_Server(ChatServiceImpl_Server):\n    async def HandlePreProcessUserQuery_Server(\n        self, query: str, messages: list[ChatServiceMessageModel], loopIndex: int",
        "detail": "server.services.ChatService_Server",
        "documentation": {}
    },
    {
        "label": "RagSearchService_Server",
        "kind": 6,
        "importPath": "server.services.RagSearchService_Server",
        "description": "server.services.RagSearchService_Server",
        "peekOfCode": "class RagSearchService_Server(RagSearchServiceImpl_Server):\n    async def SearchOnDb_Server(self, query: str) -> SearchOnDbResponseModel:\n        async with psqlDb.pool.acquire() as conn:\n            await conn.set_type_codec(\n                \"jsonb\", encoder=json.dumps, decoder=json.loads, schema=\"pg_catalog\"\n            )\n            embeddingService: Any = await EmbeddingService_Rag.ConvertTextToEmbedding(\n                text=[query]\n            )\n            queryVector = embeddingService.data[0].embedding",
        "detail": "server.services.RagSearchService_Server",
        "documentation": {}
    },
    {
        "label": "EmbeddingService_Rag",
        "kind": 5,
        "importPath": "server.services.RagSearchService_Server",
        "description": "server.services.RagSearchService_Server",
        "peekOfCode": "EmbeddingService_Rag = EmbeddingService()\nclass RagSearchService_Server(RagSearchServiceImpl_Server):\n    async def SearchOnDb_Server(self, query: str) -> SearchOnDbResponseModel:\n        async with psqlDb.pool.acquire() as conn:\n            await conn.set_type_codec(\n                \"jsonb\", encoder=json.dumps, decoder=json.loads, schema=\"pg_catalog\"\n            )\n            embeddingService: Any = await EmbeddingService_Rag.ConvertTextToEmbedding(\n                text=[query]\n            )",
        "detail": "server.services.RagSearchService_Server",
        "documentation": {}
    },
    {
        "label": "ChatServicePreProcessUserQuerySystemPropt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServicePreProcessUserQuerySystemPropt_Server = \"\"\"\nTASK\n1. Normalize the query into clear English (fix spelling/grammar, make it a proper question).\n   Example: \"who to add new drug which is not in hmis\"  \n   \"How to add a new drug in HMIS if it is not already available?\"\n2. Classify and return ONLY JSON:\n{\n  \"response\": {\n    \"cleanquery\": \"<clean sentence>\",\n    \"error\": \"OK\" | \"ABUSE_LANG_ERROR\" | \"CONTACT_INFO_ERROR\",",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceAbusiveUserQuerySystemPrompt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceAbusiveUserQuerySystemPrompt_Server = \"\"\"\nYou are a company policy enforcement assistant.\nThe user query was flagged as abusive.\nYour task: Write a short warning message to the user.\nRULES\n- Always return in **Markdown** format and preofessional clean.\n- The warning must be 610 words.\n- Clearly say that abusive or offensive words violate company policy.\n- Warn that repeated abuse may lead to account suspension or blocking.\n\"\"\"",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceConfidentialUserQuerySystemPrompt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceConfidentialUserQuerySystemPrompt_Server = \"\"\"\nYou are a company policy enforcement assistant.\nThe user query was flagged for sharing confidential or contact information.\nYour task: Write a short warning message to the user.\nRULES\n- Always return in **Markdown** format and preofessional clean.\n- The warning must be 610 words.\n- Clearly state their query included sensitive or personal details\n  (phone, email, Aadhaar, PAN, card, password, API key, etc.).\n- Say that sharing or requesting such information violates company policy and security guidelines.",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "ChatServiceUserQueryLLMSystemPropt_Server",
        "kind": 5,
        "importPath": "server.utils.ChatServiceSystemPrompt_Server",
        "description": "server.utils.ChatServiceSystemPrompt_Server",
        "peekOfCode": "ChatServiceUserQueryLLMSystemPropt_Server = \"\"\"\nYou are a helpful, concise assistant.\nGOAL\n- Answer the user's question directly and helpfully.\nSTYLE\n- Always respond in **Markdown** format.\n- Be clear and brief.\n- Use Markdown formatting (headings, lists, tables) when it improves readability and preofessional clean.\n- Use fenced code blocks for code.\nDO NOT",
        "detail": "server.utils.ChatServiceSystemPrompt_Server",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "k",
        "description": "k",
        "peekOfCode": "a = BuildRagFromDocService_Rag()\nasync def main():\n    response = await a.BuildRagFromDoc_Rag(\"./others/opd_manual.pdf\")\n    for i in response.chunkTexts:\n        print(i.text)\n        print(i.images)\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
        "detail": "k",
        "documentation": {}
    },
    {
        "label": "server",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "server = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\nserver.include_router(GragDocRouter, prefix=\"/api/v1\")\nserver.include_router(ChatRouter, prefix=\"/api/v1/ask\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "RerankingService = RerankingService()\nChatLLmService = ChatService()\nEmbeddingService = EmbeddingService()\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:server\", host=\"0.0.0.0\", port=8001, reload=True)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "ChatLLmService",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "ChatLLmService = ChatService()\nEmbeddingService = EmbeddingService()\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:server\", host=\"0.0.0.0\", port=8001, reload=True)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "EmbeddingService = EmbeddingService()\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:server\", host=\"0.0.0.0\", port=8001, reload=True)",
        "detail": "main",
        "documentation": {}
    }
]