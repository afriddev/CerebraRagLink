[
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "StreamingResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "JSONResponse",
        "importPath": "fastapi.responses",
        "description": "fastapi.responses",
        "isExtraImport": true,
        "detail": "fastapi.responses",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "importPath": "clientservices.chat.models",
        "description": "clientservices.chat.models",
        "isExtraImport": true,
        "detail": "clientservices.chat.models",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "clientservices.chat.enums",
        "description": "clientservices.chat.enums",
        "isExtraImport": true,
        "detail": "clientservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices.chat.enums",
        "description": "clientservices.chat.enums",
        "isExtraImport": true,
        "detail": "clientservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices.chat.enums",
        "description": "clientservices.chat.enums",
        "isExtraImport": true,
        "detail": "clientservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices.chat.enums",
        "description": "clientservices.chat.enums",
        "isExtraImport": true,
        "detail": "clientservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices.chat.enums",
        "description": "clientservices.chat.enums",
        "isExtraImport": true,
        "detail": "clientservices.chat.enums",
        "documentation": {}
    },
    {
        "label": "cerebras.cloud.sdk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "AsyncCerebras",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "DefaultAioHttpClient",
        "importPath": "cerebras.cloud.sdk",
        "description": "cerebras.cloud.sdk",
        "isExtraImport": true,
        "detail": "cerebras.cloud.sdk",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "importPath": "clientservices.chat.implementations",
        "description": "clientservices.chat.implementations",
        "isExtraImport": true,
        "detail": "clientservices.chat.implementations",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "clientservices.chat.workers",
        "description": "clientservices.chat.workers",
        "isExtraImport": true,
        "detail": "clientservices.chat.workers",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "importPath": "clientservices.embedding.models",
        "description": "clientservices.embedding.models",
        "isExtraImport": true,
        "detail": "clientservices.embedding.models",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "importPath": "clientservices.embedding.enums",
        "description": "clientservices.embedding.enums",
        "isExtraImport": true,
        "detail": "clientservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "clientservices.embedding.enums",
        "description": "clientservices.embedding.enums",
        "isExtraImport": true,
        "detail": "clientservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "clientservices.embedding.enums",
        "description": "clientservices.embedding.enums",
        "isExtraImport": true,
        "detail": "clientservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "clientservices.embedding.enums",
        "description": "clientservices.embedding.enums",
        "isExtraImport": true,
        "detail": "clientservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "importPath": "clientservices.embedding.enums",
        "description": "clientservices.embedding.enums",
        "isExtraImport": true,
        "detail": "clientservices.embedding.enums",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponse",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "Mistral",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "mistralai",
        "description": "mistralai",
        "isExtraImport": true,
        "detail": "mistralai",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "importPath": "clientservices.embedding.implementations",
        "description": "clientservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "clientservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "importPath": "clientservices.embedding.implementations",
        "description": "clientservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "clientservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "importPath": "clientservices.embedding.implementations",
        "description": "clientservices.embedding.implementations",
        "isExtraImport": true,
        "detail": "clientservices.embedding.implementations",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "clientservices.embedding.workers",
        "description": "clientservices.embedding.workers",
        "isExtraImport": true,
        "detail": "clientservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "importPath": "clientservices.embedding.workers",
        "description": "clientservices.embedding.workers",
        "isExtraImport": true,
        "detail": "clientservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "importPath": "clientservices.embedding.workers",
        "description": "clientservices.embedding.workers",
        "isExtraImport": true,
        "detail": "clientservices.embedding.workers",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "HandleChunkRelationExtractResponseModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "ChunkTextsModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "HandleChunkRelationExtractResponseModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "ChunkNodeModel",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "ChunkImagesData",
        "importPath": "graphrag.models",
        "description": "graphrag.models",
        "isExtraImport": true,
        "detail": "graphrag.models",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "UUID",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "unicodedata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unicodedata",
        "description": "unicodedata",
        "detail": "unicodedata",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "importPath": "clientservices",
        "description": "clientservices",
        "isExtraImport": true,
        "detail": "clientservices",
        "documentation": {}
    },
    {
        "label": "FileChunkGragImpl",
        "importPath": "graphrag.implementations",
        "description": "graphrag.implementations",
        "isExtraImport": true,
        "detail": "graphrag.implementations",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDoc",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDoc",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "ExtractEntityGragSystemPrompt",
        "importPath": "graphrag.utils.FileGragSystemPropts",
        "description": "graphrag.utils.FileGragSystemPropts",
        "isExtraImport": true,
        "detail": "graphrag.utils.FileGragSystemPropts",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersRequestModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtarctQaFromTextResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtractQaResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "HandleQaExtractResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersRequestModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "HandleQaExtractResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtractQaEmbeddingVectorModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtractQaVectorModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtarctQaFromTextResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "ExtractQaResponseModel",
        "importPath": "rag.qa.models",
        "description": "rag.qa.models",
        "isExtraImport": true,
        "detail": "rag.qa.models",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersImpl",
        "importPath": "rag.qa.implementations",
        "description": "rag.qa.implementations",
        "isExtraImport": true,
        "detail": "rag.qa.implementations",
        "documentation": {}
    },
    {
        "label": "QaDocImpl",
        "importPath": "rag.qa.implementations",
        "description": "rag.qa.implementations",
        "isExtraImport": true,
        "detail": "rag.qa.implementations",
        "documentation": {}
    },
    {
        "label": "QaAiAnswerPromptFromRagText",
        "importPath": "rag.qa.utils.qaSystemPropts",
        "description": "rag.qa.utils.qaSystemPropts",
        "isExtraImport": true,
        "detail": "rag.qa.utils.qaSystemPropts",
        "documentation": {}
    },
    {
        "label": "ExtractQaPrompt",
        "importPath": "rag.qa.utils.qaSystemPropts",
        "description": "rag.qa.utils.qaSystemPropts",
        "isExtraImport": true,
        "detail": "rag.qa.utils.qaSystemPropts",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "importPath": "server.psqldb",
        "description": "server.psqldb",
        "isExtraImport": true,
        "detail": "server.psqldb",
        "documentation": {}
    },
    {
        "label": "QaRagControllerServices",
        "importPath": "server.services",
        "description": "server.services",
        "isExtraImport": true,
        "detail": "server.services",
        "documentation": {}
    },
    {
        "label": "QaRagAskRequestModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingVectorModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "EmbeddingTextModel",
        "importPath": "server.models",
        "description": "server.models",
        "isExtraImport": true,
        "detail": "server.models",
        "documentation": {}
    },
    {
        "label": "asyncpg",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncpg",
        "description": "asyncpg",
        "detail": "asyncpg",
        "documentation": {}
    },
    {
        "label": "register_vector",
        "importPath": "pgvector.asyncpg",
        "description": "pgvector.asyncpg",
        "isExtraImport": true,
        "detail": "pgvector.asyncpg",
        "documentation": {}
    },
    {
        "label": "QaRagContollerImpl",
        "importPath": "server.implementations",
        "description": "server.implementations",
        "isExtraImport": true,
        "detail": "server.implementations",
        "documentation": {}
    },
    {
        "label": "QaDocService",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersService",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersRequestModel",
        "importPath": "rag",
        "description": "rag",
        "isExtraImport": true,
        "detail": "rag",
        "documentation": {}
    },
    {
        "label": "BaseHTTPMiddleware",
        "importPath": "starlette.middleware.base",
        "description": "starlette.middleware.base",
        "isExtraImport": true,
        "detail": "starlette.middleware.base",
        "documentation": {}
    },
    {
        "label": "RequestResponseEndpoint",
        "importPath": "starlette.middleware.base",
        "description": "starlette.middleware.base",
        "isExtraImport": true,
        "detail": "starlette.middleware.base",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "fitz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "fitz",
        "description": "fitz",
        "detail": "fitz",
        "documentation": {}
    },
    {
        "label": "FileChunkGragService",
        "importPath": "graphrag",
        "description": "graphrag",
        "isExtraImport": true,
        "detail": "graphrag",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "asynccontextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "QaRag",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "CustomMidlleware",
        "importPath": "server",
        "description": "server",
        "isExtraImport": true,
        "detail": "server",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageRoleEnum",
        "kind": 6,
        "importPath": "clientservices.chat.enums.ChatServiceEnums",
        "description": "clientservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTANT = \"assistant\"\nclass ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")",
        "detail": "clientservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseStatusEnum",
        "kind": 6,
        "importPath": "clientservices.chat.enums.ChatServiceEnums",
        "description": "clientservices.chat.enums.ChatServiceEnums",
        "peekOfCode": "class ChatServiceResponseStatusEnum(Enum):\n    SUCCESS = (200, \"SUCCESS\")\n    BAD_REQUEST = (400, \"BAD_REQUEST\")\n    UNAUTHROZIED = (401, \"UNAUTHROZIED\")\n    PERMISSION_DENIED = (403, \"PERMISSION_DENIED\")\n    NOT_FOUND = (404, \"NOT_FOUND\")\n    REQUEST_TIMEOUT = (408, \"REQUEST_TIMEOUT\")\n    CONFLICT = (409, \"CONFLICT\")\n    ENTITY_ERROR = (422, \"ENTITY_ERROR\")\n    RATE_LIMIT = (429, \"RATE_LIMIT\")",
        "detail": "clientservices.chat.enums.ChatServiceEnums",
        "documentation": {}
    },
    {
        "label": "ChatServiceImpl",
        "kind": 6,
        "importPath": "clientservices.chat.implementations.ChatServiceImplementation",
        "description": "clientservices.chat.implementations.ChatServiceImplementation",
        "peekOfCode": "class ChatServiceImpl(ABC):\n    @abstractmethod\n    async def Chat(self, modelParams: ChatServiceRequestModel) -> ChatServiceResponseModel | StreamingResponse:\n        pass\n    @abstractmethod\n    def HandleApiStatusError(\n        self, statusCode: int\n    ) -> ChatServiceResponseModel :\n        pass",
        "detail": "clientservices.chat.implementations.ChatServiceImplementation",
        "documentation": {}
    },
    {
        "label": "ChatServiceMessageModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceMessageModel(BaseModel):\n    role: Optional[ChatServiceMessageRoleEnum] = ChatServiceMessageRoleEnum.USER\n    content: str\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel(BaseModel):\n    type: str | int | float | str\n    items: Optional[Any] = None\n    properties: Optional[Any] = None\n    required: Optional[Any] = None\n    additionalProperties: Optional[Any] = None\nclass ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel(BaseModel):\n    type: str = \"object\"\n    properties: dict[str, ChatServiceCerebrasFormatJsonSchemaJsonSchemaPropertyModel] = {}\n    required: List[str] = []\n    additionalProperties: bool = False\nclass ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatJsonSchemaModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatJsonSchemaModel(BaseModel):\n    name: str = \"schema\"\n    strict: bool = True\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaJsonSchemaModel\nclass ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceCerebrasFormatModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceCerebrasFormatModel(BaseModel):\n    type: str = \"json_schema\"\n    jsonSchema: ChatServiceCerebrasFormatJsonSchemaModel\nclass ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceRequestModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceRequestModel(BaseModel):\n    model: str = \"gpt-oss-120b\"\n    messages: List[ChatServiceMessageModel]\n    maxCompletionTokens: Optional[int] = 20000\n    stream: Optional[bool] = False\n    temperature: Optional[float] = 0.7\n    apiKey: str\n    responseFormat: Optional[ChatServiceCerebrasFormatModel] = None\nclass ChatServiceChoiceMessageModel(BaseModel):\n    role: ChatServiceMessageRoleEnum = ChatServiceMessageRoleEnum.ASSISTANT",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceMessageModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceMessageModel(BaseModel):\n    role: ChatServiceMessageRoleEnum = ChatServiceMessageRoleEnum.ASSISTANT\n    content: str\nclass ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceChoiceModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceChoiceModel(BaseModel):\n    index: int = 0\n    message: ChatServiceChoiceMessageModel\nclass ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceUsageModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceUsageModel(BaseModel):\n    promptTokens: int | None = None\n    completionTokens: int | None = None\n    totalTokens: int | None = None\nclass ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceDataResponseModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceDataResponseModel(BaseModel):  \n    id: str\n    choices: List[ChatServiceChoiceModel] = []\n    created: int\n    model: str = \"llama-3.3-70b\"\n    totalTime: float = 0.0\n    usage: ChatServiceUsageModel\nclass ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatServiceResponseModel",
        "kind": 6,
        "importPath": "clientservices.chat.models.ChatServiceModels",
        "description": "clientservices.chat.models.ChatServiceModels",
        "peekOfCode": "class ChatServiceResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    LLMData: ChatServiceDataResponseModel | None = None",
        "detail": "clientservices.chat.models.ChatServiceModels",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "kind": 6,
        "importPath": "clientservices.chat.services.ChatServices",
        "description": "clientservices.chat.services.ChatServices",
        "peekOfCode": "class ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,\n            404: ChatServiceResponseStatusEnum.NOT_FOUND,\n        }\n        message = errorCodes.get(statusCode, ChatServiceResponseStatusEnum.SERVER_ERROR)\n        return ChatServiceResponseModel(status=message)",
        "detail": "clientservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "clientservices.chat.services.ChatServices",
        "description": "clientservices.chat.services.ChatServices",
        "peekOfCode": "client = AsyncCerebras(\n    api_key=GetCerebrasApiKey(),\n    http_client=DefaultAioHttpClient(),\n)\nclass ChatService(ChatServiceImpl):\n    def HandleApiStatusError(self, statusCode: int) -> ChatServiceResponseModel:\n        errorCodes = {\n            400: ChatServiceResponseStatusEnum.BAD_REQUEST,\n            401: ChatServiceResponseStatusEnum.UNAUTHROZIED,\n            403: ChatServiceResponseStatusEnum.PERMISSION_DENIED,",
        "detail": "clientservices.chat.services.ChatServices",
        "documentation": {}
    },
    {
        "label": "GetCerebrasApiKey",
        "kind": 2,
        "importPath": "clientservices.chat.workers.GetApiKey",
        "description": "clientservices.chat.workers.GetApiKey",
        "peekOfCode": "def GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "clientservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "CEREBRAS_API_KEY",
        "kind": 5,
        "importPath": "clientservices.chat.workers.GetApiKey",
        "description": "clientservices.chat.workers.GetApiKey",
        "peekOfCode": "CEREBRAS_API_KEY = cast(Any, os.getenv(\"CEREBRAS_API_KEY\"))\ndef GetCerebrasApiKey() ->str:\n    return CEREBRAS_API_KEY",
        "detail": "clientservices.chat.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MistralChatMessageRoleEnum",
        "kind": 6,
        "importPath": "clientservices.embedding.enums.ChatEnums",
        "description": "clientservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatMessageRoleEnum(Enum):\n    USER = \"user\"\n    SYSTEM = \"system\"\n    ASSISTENT = \"assistant\"\nclass MistralChatResponseStatusEnum(Enum):\n    ERROR  = (500,\"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")",
        "detail": "clientservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseStatusEnum",
        "kind": 6,
        "importPath": "clientservices.embedding.enums.ChatEnums",
        "description": "clientservices.embedding.enums.ChatEnums",
        "peekOfCode": "class MistralChatResponseStatusEnum(Enum):\n    ERROR  = (500,\"ERROR\")\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")",
        "detail": "clientservices.embedding.enums.ChatEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseEnum",
        "kind": 6,
        "importPath": "clientservices.embedding.enums.EmbeddingEnums",
        "description": "clientservices.embedding.enums.EmbeddingEnums",
        "peekOfCode": "class EmbeddingResponseEnum(Enum):\n    VALIDATION_ERROR = (422, \"VALIDATION_ERROR\")\n    SERVER_ERROR = (500, \"SERVER_ERROR\")\n    SUCCESS = (200, \"SUCCESS\")",
        "detail": "clientservices.embedding.enums.EmbeddingEnums",
        "documentation": {}
    },
    {
        "label": "EmbeddingServiceImpl",
        "kind": 6,
        "importPath": "clientservices.embedding.implementations.EmbeddingServiceimplementation",
        "description": "clientservices.embedding.implementations.EmbeddingServiceimplementation",
        "peekOfCode": "class EmbeddingServiceImpl(ABC):\n    @abstractmethod\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        pass\n    @abstractmethod\n    def FindSimilarity(self, vec1: list[float], vec2: list[float]) -> float:\n        pass",
        "detail": "clientservices.embedding.implementations.EmbeddingServiceimplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatImpl",
        "kind": 6,
        "importPath": "clientservices.embedding.implementations.MistralChatImpl",
        "description": "clientservices.embedding.implementations.MistralChatImpl",
        "peekOfCode": "class MistralChatImpl(ABC):\n    @abstractmethod\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        pass",
        "detail": "clientservices.embedding.implementations.MistralChatImpl",
        "documentation": {}
    },
    {
        "label": "RerankingImpl",
        "kind": 6,
        "importPath": "clientservices.embedding.implementations.RerankingImplementation",
        "description": "clientservices.embedding.implementations.RerankingImplementation",
        "peekOfCode": "class RerankingImpl(ABC):\n    @abstractmethod\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        pass\n    @abstractmethod\n    def FindTopKResultsFromVectors(self,request:FindTopKresultsFromVectorsRequestModel) -> FindTopKresultsFromVectorsResponseModel:\n        pass",
        "detail": "clientservices.embedding.implementations.RerankingImplementation",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestMessageModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestMessageModel(BaseModel):\n    role: MistralChatMessageRoleEnum = MistralChatMessageRoleEnum.USER\n    content: str | list[str]\nclass MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatRequestModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatRequestModel(BaseModel):\n    model: str = \"mistral-small-2506\"\n    temperature: float = 0.7\n    maxTokens: int = 30000\n    stream: bool = False\n    messages: list[MistralChatRequestMessageModel]\n    responseFormat: Any | None = None\nclass MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseUsageModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseUsageModel(BaseModel):\n    promptTokens: int\n    completionToken: int\n    totalTokens: int\nclass MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseMessageModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseMessageModel(BaseModel):\n    content: str\n    role: str | None = None\nclass MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseChoiceModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseChoiceModel(BaseModel):\n    index: int\n    message: MistralChatResponseMessageModel\nclass MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "MistralChatResponseModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.ChatModels",
        "description": "clientservices.embedding.models.ChatModels",
        "peekOfCode": "class MistralChatResponseModel(BaseModel):\n    id: str | None = None\n    model: str | None = None\n    usgae: MistralChatResponseUsageModel | None = None\n    created: int | None = None\n    choices: list[MistralChatResponseChoiceModel] | None = None\n    status:MistralChatResponseStatusEnum",
        "detail": "clientservices.embedding.models.ChatModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingUsageModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.EmbeddingModels",
        "description": "clientservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingUsageModel(BaseModel):\n    promptTokens: int | None\n    completionTokens: int | None\n    totalTokens: int | None\nclass EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR",
        "detail": "clientservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingDataModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.EmbeddingModels",
        "description": "clientservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingDataModel(BaseModel):\n    index: int | None\n    embedding: list[float] | None\nclass EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None",
        "detail": "clientservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingResponseModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.EmbeddingModels",
        "description": "clientservices.embedding.models.EmbeddingModels",
        "peekOfCode": "class EmbeddingResponseModel(BaseModel):\n    status: EmbeddingResponseEnum = (\n        EmbeddingResponseEnum.VALIDATION_ERROR\n    )\n    id: str | None = None\n    model: str  | None = None\n    usage: EmbeddingUsageModel | None = None\n    data: list[EmbeddingDataModel] | None = None",
        "detail": "clientservices.embedding.models.EmbeddingModels",
        "documentation": {}
    },
    {
        "label": "RerankingRequestModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingRequestModel(BaseModel):\n    model: str = \"jina-reranker-m0\"\n    query: str\n    docs: list[str]\n    topN: int = 5\n    returnDocuments: bool = False\nclass RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseChoiseModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseChoiseModel(BaseModel):\n    index: int\n    score: float\nclass RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingUsageModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingUsageModel(BaseModel):\n    totalTokens: int\nclass RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "RerankingResponseModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class RerankingResponseModel(BaseModel):\n    response: list[RerankingResponseChoiseModel] | None = None\n    status: ChatServiceResponseStatusEnum = ChatServiceResponseStatusEnum.SUCCESS\n    usage: RerankingUsageModel | None = None\nclass FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsRequestModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsRequestModel(BaseModel):\n    sourceVectors: list[list[float]]\n    queryVector: list[float]\n    topK: int = 20\nclass FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "FindTopKresultsFromVectorsResponseModel",
        "kind": 6,
        "importPath": "clientservices.embedding.models.RerankingModels",
        "description": "clientservices.embedding.models.RerankingModels",
        "peekOfCode": "class FindTopKresultsFromVectorsResponseModel(BaseModel):\n    distances:list[float] | None = None\n    indeces:list[int] | None = None",
        "detail": "clientservices.embedding.models.RerankingModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingService",
        "kind": 6,
        "importPath": "clientservices.embedding.services.EmbeddingService",
        "description": "clientservices.embedding.services.EmbeddingService",
        "peekOfCode": "class EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(\n                    embedding=obj.embedding,",
        "detail": "clientservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "mistralClient",
        "kind": 5,
        "importPath": "clientservices.embedding.services.EmbeddingService",
        "description": "clientservices.embedding.services.EmbeddingService",
        "peekOfCode": "mistralClient = Mistral(api_key=GetMistralApiKey())\nclass EmbeddingService(EmbeddingServiceImpl):\n    async def ConvertTextToEmbedding(self, text: list[str]) -> EmbeddingResponseModel:\n        try:\n            res: EmbeddingResponse = await mistralClient.embeddings.create_async(\n                model=\"mistral-embed\",\n                inputs=text,\n            )\n            data = [\n                EmbeddingDataModel(",
        "detail": "clientservices.embedding.services.EmbeddingService",
        "documentation": {}
    },
    {
        "label": "MistralChatService",
        "kind": 6,
        "importPath": "clientservices.embedding.services.MistralChatService",
        "description": "clientservices.embedding.services.MistralChatService",
        "peekOfCode": "class MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}\n                )",
        "detail": "clientservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "mistral",
        "kind": 5,
        "importPath": "clientservices.embedding.services.MistralChatService",
        "description": "clientservices.embedding.services.MistralChatService",
        "peekOfCode": "mistral = Mistral(api_key=GetMistralApiKey())\nclass MistralChatService(MistralChatImpl):\n    async def Chat(\n        self, modelParams: MistralChatRequestModel\n    ) -> MistralChatResponseModel:\n        try:\n            messages: Any = []\n            for message in modelParams.messages:\n                messages.append(\n                    {\"role\": message.role.value, \"content\": message.content}",
        "detail": "clientservices.embedding.services.MistralChatService",
        "documentation": {}
    },
    {
        "label": "RerankingService",
        "kind": 6,
        "importPath": "clientservices.embedding.services.RerankingService",
        "description": "clientservices.embedding.services.RerankingService",
        "peekOfCode": "class RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel\n    ) -> RerankingResponseModel:\n        try:\n            data: Any = {\n                \"model\": modelParams.model,\n                \"query\": modelParams.query,\n                \"documents\": modelParams.docs,\n                \"top_n\": modelParams.topN,",
        "detail": "clientservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "jinaClient",
        "kind": 5,
        "importPath": "clientservices.embedding.services.RerankingService",
        "description": "clientservices.embedding.services.RerankingService",
        "peekOfCode": "jinaClient = requests.Session()\njinaClient.headers.update(\n    {\n        \"Authorization\": f\"Bearer {GetJinaApiKey()}\",\n        \"Content-Type\": \"application/json\",\n    }\n)\nclass RerankingService(RerankingImpl):\n    async def FindRankingScore(\n        self, modelParams: RerankingRequestModel",
        "detail": "clientservices.embedding.services.RerankingService",
        "documentation": {}
    },
    {
        "label": "GetMistralApiKey",
        "kind": 2,
        "importPath": "clientservices.embedding.workers.GetApiKey",
        "description": "clientservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetMistralApiKey() -> str:\n    return MISTARL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "clientservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "GetJinaApiKey",
        "kind": 2,
        "importPath": "clientservices.embedding.workers.GetApiKey",
        "description": "clientservices.embedding.workers.GetApiKey",
        "peekOfCode": "def GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "clientservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "MISTARL_API_KEY",
        "kind": 5,
        "importPath": "clientservices.embedding.workers.GetApiKey",
        "description": "clientservices.embedding.workers.GetApiKey",
        "peekOfCode": "MISTARL_API_KEY = cast(Any, os.getenv(\"MISTRAL_API_KEY\"))\nJINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTARL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "clientservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "JINA_API_KEY",
        "kind": 5,
        "importPath": "clientservices.embedding.workers.GetApiKey",
        "description": "clientservices.embedding.workers.GetApiKey",
        "peekOfCode": "JINA_API_KEY = cast(Any, os.getenv(\"JINA_API_KEY\"))\ndef GetMistralApiKey() -> str:\n    return MISTARL_API_KEY\ndef GetJinaApiKey() -> str:\n    return JINA_API_KEY",
        "detail": "clientservices.embedding.workers.GetApiKey",
        "documentation": {}
    },
    {
        "label": "FileChunkGragImpl",
        "kind": 6,
        "importPath": "graphrag.implementations.FileChunkGragImpl",
        "description": "graphrag.implementations.FileChunkGragImpl",
        "peekOfCode": "class FileChunkGragImpl(ABC):\n    @abstractmethod\n    def ExatrctChunkFromText(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        pass\n    @abstractmethod\n    async def handleKgChunkRelationExtarctProcess(\n        self, file: str\n    ) -> HandleChunkRelationExtractResponseModel:",
        "detail": "graphrag.implementations.FileChunkGragImpl",
        "documentation": {}
    },
    {
        "label": "LLMGragEntityResponseModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class LLMGragEntityResponseModel(BaseModel):\n    relations: list[list[str]]\n    relationshipsEntities: list[list[list[str]]]\n    chunk: list[str]\nclass ChunkNodeModel(BaseModel):\n    score: float\n    chunkId: UUID\nclass ChunkImagesData(BaseModel):\n    sectionNumber: str\n    title: str",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "ChunkNodeModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class ChunkNodeModel(BaseModel):\n    score: float\n    chunkId: UUID\nclass ChunkImagesData(BaseModel):\n    sectionNumber: str\n    title: str\n    image: str\n    description: str\nclass ChunkTextsModel(BaseModel):\n    id: UUID",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "ChunkImagesData",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class ChunkImagesData(BaseModel):\n    sectionNumber: str\n    title: str\n    image: str\n    description: str\nclass ChunkTextsModel(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    entities: list[str]",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "ChunkTextsModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class ChunkTextsModel(BaseModel):\n    id: UUID\n    text: str\n    vector: list[float] | None = None\n    entities: list[str]\n    questions: list[str]\n    questionVectors: list[list[float]] | None = []\n    matchedNodes: list[ChunkNodeModel] | None = None\n    images: list[ChunkImagesData] | None = None\nclass ChunkRelationModel(BaseModel):",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "ChunkRelationModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class ChunkRelationModel(BaseModel):\n    id: UUID\n    realtion: str\n    realtionEntites: list[str]\n    relationVector: list[float] | None = None\nclass ChunkRelationsModel(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel]\nclass HandleChunkRelationExtractResponseModel(BaseModel):\n    chunkTexts: list[ChunkTextsModel]",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "ChunkRelationsModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class ChunkRelationsModel(BaseModel):\n    chunkId: UUID\n    chunkRelations: list[ChunkRelationModel]\nclass HandleChunkRelationExtractResponseModel(BaseModel):\n    chunkTexts: list[ChunkTextsModel]\n    chunkRelations: list[ChunkRelationsModel]",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "HandleChunkRelationExtractResponseModel",
        "kind": 6,
        "importPath": "graphrag.models.FileChunkGragModels",
        "description": "graphrag.models.FileChunkGragModels",
        "peekOfCode": "class HandleChunkRelationExtractResponseModel(BaseModel):\n    chunkTexts: list[ChunkTextsModel]\n    chunkRelations: list[ChunkRelationsModel]",
        "detail": "graphrag.models.FileChunkGragModels",
        "documentation": {}
    },
    {
        "label": "FileChunkGragService",
        "kind": 6,
        "importPath": "graphrag.services.FileChunkGragService",
        "description": "graphrag.services.FileChunkGragService",
        "peekOfCode": "class FileChunkGragService(FileChunkGragImpl):\n    def ExatrctChunkFromText(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")\n        _HYPHEN_BREAK_RE = re.compile(r\"(\\w)-\\n(\\w)\")\n        _MULTI_NL_RE = re.compile(r\"\\n{3,}\")",
        "detail": "graphrag.services.FileChunkGragService",
        "documentation": {}
    },
    {
        "label": "chatService",
        "kind": 5,
        "importPath": "graphrag.services.FileChunkGragService",
        "description": "graphrag.services.FileChunkGragService",
        "peekOfCode": "chatService = ChatService()\nembeddingService = EmbeddingService()\nrerankingService = RerankingService()\nclass FileChunkGragService(FileChunkGragImpl):\n    def ExatrctChunkFromText(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)",
        "detail": "graphrag.services.FileChunkGragService",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "graphrag.services.FileChunkGragService",
        "description": "graphrag.services.FileChunkGragService",
        "peekOfCode": "embeddingService = EmbeddingService()\nrerankingService = RerankingService()\nclass FileChunkGragService(FileChunkGragImpl):\n    def ExatrctChunkFromText(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")",
        "detail": "graphrag.services.FileChunkGragService",
        "documentation": {}
    },
    {
        "label": "rerankingService",
        "kind": 5,
        "importPath": "graphrag.services.FileChunkGragService",
        "description": "graphrag.services.FileChunkGragService",
        "peekOfCode": "rerankingService = RerankingService()\nclass FileChunkGragService(FileChunkGragImpl):\n    def ExatrctChunkFromText(\n        self, file: str, chunkSize: int, chunkOLSize: int | None = 0\n    ) -> Tuple[list[str], list[str]]:\n        _PAGE_RE = re.compile(r\"\\bpage\\s+\\d+\\s+of\\s+\\d+\\b\", re.IGNORECASE)\n        _IMAGE_RE = re.compile(r\"\\s*(<<IMAGE-\\d+>>)\\s*\", re.IGNORECASE)\n        _BULLET_LINE_RE = re.compile(r\"^[\\s\\-\\*\\u2022\\uf0b7F]+(?=\\S)\", re.MULTILINE)\n        _SOFT_HYPHEN_RE = re.compile(r\"\\u00AD\")\n        _HYPHEN_BREAK_RE = re.compile(r\"(\\w)-\\n(\\w)\")",
        "detail": "graphrag.services.FileChunkGragService",
        "documentation": {}
    },
    {
        "label": "ExtractEntityGragSystemPrompt",
        "kind": 5,
        "importPath": "graphrag.utils.FileGragSystemPropts",
        "description": "graphrag.utils.FileGragSystemPropts",
        "peekOfCode": "ExtractEntityGragSystemPrompt = r\"\"\"\nTASK\nReturn ONLY valid JSON per the schema for ONE input chunk.\nINPUT\n{ \"chunk\": \"...\" }\nOUTPUT (conceptual)\n{\n  \"response\": {\n    \"entities\": [\"...\"],\n    \"relations\": [\"...\"],",
        "detail": "graphrag.utils.FileGragSystemPropts",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersImpl",
        "kind": 6,
        "importPath": "rag.qa.implementations.QaAiAnswersImpl",
        "description": "rag.qa.implementations.QaAiAnswersImpl",
        "peekOfCode": "class QaAiAnswersImpl(ABC):\n    @abstractmethod\n    async def QaResponse(\n        self,\n        request: QaAiAnswersRequestModel,\n    ) ->  QaAiAnswersResponseModel:\n        pass",
        "detail": "rag.qa.implementations.QaAiAnswersImpl",
        "documentation": {}
    },
    {
        "label": "QaDocImpl",
        "kind": 6,
        "importPath": "rag.qa.implementations.QaDocImpl",
        "description": "rag.qa.implementations.QaDocImpl",
        "peekOfCode": "class QaDocImpl(ABC):\n    @abstractmethod\n    async def ExtractQaFromText(\n        self, text: str\n    ) -> ExtarctQaFromTextResponseModel:\n        pass\n    @abstractmethod\n    async def ExtractQa(\n        self, file: str\n    ) -> ExtractQaResponseModel:",
        "detail": "rag.qa.implementations.QaDocImpl",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersRequestModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaAiAnswersModels",
        "description": "rag.qa.models.QaAiAnswersModels",
        "peekOfCode": "class QaAiAnswersRequestModel(BaseModel):\n    ragResponseText: str\n    query: str\nclass QaAiAnswersResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum\n    response: str | None",
        "detail": "rag.qa.models.QaAiAnswersModels",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersResponseModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaAiAnswersModels",
        "description": "rag.qa.models.QaAiAnswersModels",
        "peekOfCode": "class QaAiAnswersResponseModel(BaseModel):\n    status: ChatServiceResponseStatusEnum\n    response: str | None",
        "detail": "rag.qa.models.QaAiAnswersModels",
        "documentation": {}
    },
    {
        "label": "ExtractQaEmbeddingTextModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class ExtractQaEmbeddingTextModel(BaseModel):\n    question: str\n    answer: str\n    embeddingText: str\nclass ExtractQaVectorModel(BaseModel):\n    embeddingVector: list[float]\n    id: UUID\n    embeddingId: UUID\nclass ExtarctQaFromTextResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "ExtractQaVectorModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class ExtractQaVectorModel(BaseModel):\n    embeddingVector: list[float]\n    id: UUID\n    embeddingId: UUID\nclass ExtarctQaFromTextResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None\n    status: ChatServiceResponseStatusEnum\nclass ExtractQaResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None\n    status: ChatServiceResponseStatusEnum",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "ExtarctQaFromTextResponseModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class ExtarctQaFromTextResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None\n    status: ChatServiceResponseStatusEnum\nclass ExtractQaResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None\n    status: ChatServiceResponseStatusEnum\nclass ExtractQaEmbeddingVectorModel(\n    ExtractQaEmbeddingTextModel\n):\n    id: UUID",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "ExtractQaResponseModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class ExtractQaResponseModel(BaseModel):\n    response: list[ExtractQaEmbeddingTextModel] | None = None\n    status: ChatServiceResponseStatusEnum\nclass ExtractQaEmbeddingVectorModel(\n    ExtractQaEmbeddingTextModel\n):\n    id: UUID\n    vectorId: UUID\nclass HandleQaExtractResponseModel(BaseModel):\n    questionAndAnsers: list[ExtractQaEmbeddingVectorModel] | None = None",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "ExtractQaEmbeddingVectorModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class ExtractQaEmbeddingVectorModel(\n    ExtractQaEmbeddingTextModel\n):\n    id: UUID\n    vectorId: UUID\nclass HandleQaExtractResponseModel(BaseModel):\n    questionAndAnsers: list[ExtractQaEmbeddingVectorModel] | None = None\n    status: ChatServiceResponseStatusEnum | EmbeddingResponseEnum\n    vectors: list[ExtractQaVectorModel] | None = None",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "HandleQaExtractResponseModel",
        "kind": 6,
        "importPath": "rag.qa.models.QaDocModels",
        "description": "rag.qa.models.QaDocModels",
        "peekOfCode": "class HandleQaExtractResponseModel(BaseModel):\n    questionAndAnsers: list[ExtractQaEmbeddingVectorModel] | None = None\n    status: ChatServiceResponseStatusEnum | EmbeddingResponseEnum\n    vectors: list[ExtractQaVectorModel] | None = None",
        "detail": "rag.qa.models.QaDocModels",
        "documentation": {}
    },
    {
        "label": "QaAiAnswersService",
        "kind": 6,
        "importPath": "rag.qa.services.QaAiAnswersImplService",
        "description": "rag.qa.services.QaAiAnswersImplService",
        "peekOfCode": "class QaAiAnswersService(QaAiAnswersImpl):\n    async def QaResponse(\n        self, request: QaAiAnswersRequestModel\n    ) ->  QaAiAnswersResponseModel:\n        llmMessages: list[ChatServiceMessageModel] = []\n        llmMessages.append(\n            ChatServiceMessageModel(\n                role=ChatServiceMessageRoleEnum.SYSTEM,\n                content=QaAiAnswerPromptFromRagText,\n            )",
        "detail": "rag.qa.services.QaAiAnswersImplService",
        "documentation": {}
    },
    {
        "label": "ChatServices",
        "kind": 5,
        "importPath": "rag.qa.services.QaAiAnswersImplService",
        "description": "rag.qa.services.QaAiAnswersImplService",
        "peekOfCode": "ChatServices = ChatService()\nclass QaAiAnswersService(QaAiAnswersImpl):\n    async def QaResponse(\n        self, request: QaAiAnswersRequestModel\n    ) ->  QaAiAnswersResponseModel:\n        llmMessages: list[ChatServiceMessageModel] = []\n        llmMessages.append(\n            ChatServiceMessageModel(\n                role=ChatServiceMessageRoleEnum.SYSTEM,\n                content=QaAiAnswerPromptFromRagText,",
        "detail": "rag.qa.services.QaAiAnswersImplService",
        "documentation": {}
    },
    {
        "label": "QaDocService",
        "kind": 6,
        "importPath": "rag.qa.services.QaDocServices",
        "description": "rag.qa.services.QaDocServices",
        "peekOfCode": "class QaDocService(QaDocImpl):\n    async def ExtractQaFromText(self, text: str) -> ExtarctQaFromTextResponseModel:\n        systemPrompt = ExtractQaPrompt\n        messages = [\n            ChatServiceMessageModel(role=ChatServiceMessageRoleEnum.SYSTEM, content=systemPrompt),\n            ChatServiceMessageModel(\n                role=ChatServiceMessageRoleEnum.USER, content=text\n            ),  # your PDF-extracted text here\n        ]\n        LLMResponse: Any = await ChatService.Chat(",
        "detail": "rag.qa.services.QaDocServices",
        "documentation": {}
    },
    {
        "label": "ChatService",
        "kind": 5,
        "importPath": "rag.qa.services.QaDocServices",
        "description": "rag.qa.services.QaDocServices",
        "peekOfCode": "ChatService = ChatService()\nembeddingService = EmbeddingService()\nclass QaDocService(QaDocImpl):\n    async def ExtractQaFromText(self, text: str) -> ExtarctQaFromTextResponseModel:\n        systemPrompt = ExtractQaPrompt\n        messages = [\n            ChatServiceMessageModel(role=ChatServiceMessageRoleEnum.SYSTEM, content=systemPrompt),\n            ChatServiceMessageModel(\n                role=ChatServiceMessageRoleEnum.USER, content=text\n            ),  # your PDF-extracted text here",
        "detail": "rag.qa.services.QaDocServices",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "rag.qa.services.QaDocServices",
        "description": "rag.qa.services.QaDocServices",
        "peekOfCode": "embeddingService = EmbeddingService()\nclass QaDocService(QaDocImpl):\n    async def ExtractQaFromText(self, text: str) -> ExtarctQaFromTextResponseModel:\n        systemPrompt = ExtractQaPrompt\n        messages = [\n            ChatServiceMessageModel(role=ChatServiceMessageRoleEnum.SYSTEM, content=systemPrompt),\n            ChatServiceMessageModel(\n                role=ChatServiceMessageRoleEnum.USER, content=text\n            ),  # your PDF-extracted text here\n        ]",
        "detail": "rag.qa.services.QaDocServices",
        "documentation": {}
    },
    {
        "label": "ExtractQaPrompt",
        "kind": 5,
        "importPath": "rag.qa.utils.qaSystemPropts",
        "description": "rag.qa.utils.qaSystemPropts",
        "peekOfCode": "ExtractQaPrompt = \"\"\"\nYou are an expert information extraction assistant for building a vector-searchable QA knowledge base.\nYour task:\n- Read the given text (FAQ, documentation, or user guide).\n- For each question-answer pair in the text, extract:\n    1. `question`: Use the question text exactly as written in the text.\n    2. `answer`: Use the answer text exactly as written (verbatim, do not summarize or alter).\n    3. `embeddingText`: Create a concise, enriched version of the question for vector search.\n        - Start with the original question.\n        - Add related terms, synonyms, and key entities from the answer.",
        "detail": "rag.qa.utils.qaSystemPropts",
        "documentation": {}
    },
    {
        "label": "QaAiAnswerPromptFromRagText",
        "kind": 5,
        "importPath": "rag.qa.utils.qaSystemPropts",
        "description": "rag.qa.utils.qaSystemPropts",
        "peekOfCode": "QaAiAnswerPromptFromRagText = \"\"\"\nYou are an AI assistant. I will provide you with some context from a database related to the user query.\n- If the context is relevant, answer ONLY based on that context.  \n- If the context does not contain relevant information, you may answer using your own knowledge.  \n- If the users query is unrelated to the context, ignore the context and respond normally.  \n Important instructions for output:\n- Respond ONLY with the final answer.  \n- Do NOT use Markdown (**bold**, ## headings, bullet points, etc.).  \n- Do NOT add <think>, XML, JSON, or any other tags.  \n- Do NOT include quotes around the text.  ",
        "detail": "rag.qa.utils.qaSystemPropts",
        "documentation": {}
    },
    {
        "label": "QaTestModel",
        "kind": 6,
        "importPath": "server.controllers.QaRagController",
        "description": "server.controllers.QaRagController",
        "peekOfCode": "class QaTestModel(BaseModel):\n    answer:str\n    question:str\nQaRag = APIRouter()\nQaRaServices = QaRagControllerServices()\nasync def getDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@QaRag.get(\"/rag/extarct\")\nasync def HandleQaRag():",
        "detail": "server.controllers.QaRagController",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "server.controllers.QaRagController",
        "description": "server.controllers.QaRagController",
        "peekOfCode": "embeddingService = EmbeddingService()\nclass QaTestModel(BaseModel):\n    answer:str\n    question:str\nQaRag = APIRouter()\nQaRaServices = QaRagControllerServices()\nasync def getDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@QaRag.get(\"/rag/extarct\")",
        "detail": "server.controllers.QaRagController",
        "documentation": {}
    },
    {
        "label": "QaRag",
        "kind": 5,
        "importPath": "server.controllers.QaRagController",
        "description": "server.controllers.QaRagController",
        "peekOfCode": "QaRag = APIRouter()\nQaRaServices = QaRagControllerServices()\nasync def getDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@QaRag.get(\"/rag/extarct\")\nasync def HandleQaRag():\n    response = await QaRaServices.QaRagExtract(await getDb())\n    return response\n@QaRag.post(\"/rag/ask\")",
        "detail": "server.controllers.QaRagController",
        "documentation": {}
    },
    {
        "label": "QaRaServices",
        "kind": 5,
        "importPath": "server.controllers.QaRagController",
        "description": "server.controllers.QaRagController",
        "peekOfCode": "QaRaServices = QaRagControllerServices()\nasync def getDb() -> PsqlDb:\n    from main import psqlDb\n    return psqlDb\n@QaRag.get(\"/rag/extarct\")\nasync def HandleQaRag():\n    response = await QaRaServices.QaRagExtract(await getDb())\n    return response\n@QaRag.post(\"/rag/ask\")\nasync def HandleQaRagAsk(request: QaRagAskRequestModel):",
        "detail": "server.controllers.QaRagController",
        "documentation": {}
    },
    {
        "label": "qa_embedding_texts_query",
        "kind": 5,
        "importPath": "server.controllers.QaRagQuerys",
        "description": "server.controllers.QaRagQuerys",
        "peekOfCode": "qa_embedding_texts_query = \"\"\"\nCREATE TABLE IF NOT EXISTS qa_embedding_texts (\n    id UUID PRIMARY KEY,\n    vector_id UUID NOT NULL,\n    question TEXT NOT NULL,\n    answer TEXT NOT NULL,\n    embedding_text TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\"\"\"",
        "detail": "server.controllers.QaRagQuerys",
        "documentation": {}
    },
    {
        "label": "qa_embedding_vectors_query",
        "kind": 5,
        "importPath": "server.controllers.QaRagQuerys",
        "description": "server.controllers.QaRagQuerys",
        "peekOfCode": "qa_embedding_vectors_query = \"\"\"\nCREATE TABLE IF NOT EXISTS qa_embedding_vectors (\n    id UUID PRIMARY KEY,\n    embedding_id UUID NOT NULL,  \n    embedding_vector vector(1024) NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\"\"\"\nqa_embedding_vector_index_query = \"\"\"\nCREATE INDEX IF NOT EXISTS qa_embedding_vectors_embedding_idx",
        "detail": "server.controllers.QaRagQuerys",
        "documentation": {}
    },
    {
        "label": "qa_embedding_vector_index_query",
        "kind": 5,
        "importPath": "server.controllers.QaRagQuerys",
        "description": "server.controllers.QaRagQuerys",
        "peekOfCode": "qa_embedding_vector_index_query = \"\"\"\nCREATE INDEX IF NOT EXISTS qa_embedding_vectors_embedding_idx\nON qa_embedding_vectors\nUSING hnsw (embedding_vector vector_cosine_ops);\n\"\"\"\n\"\"\"\nCREATE TABLE IF NOT EXISTS qa_embedding_texts (\n    id UUID PRIMARY KEY,\n    vector_id UUID NOT NULL,\n    question TEXT NOT NULL,",
        "detail": "server.controllers.QaRagQuerys",
        "documentation": {}
    },
    {
        "label": "QaRagContollerImpl",
        "kind": 6,
        "importPath": "server.implementations.QaRagImpl",
        "description": "server.implementations.QaRagImpl",
        "peekOfCode": "class QaRagContollerImpl(ABC):\n    @abstractmethod\n    async def QaRagExtract(self,db:Any) -> JSONResponse:\n        pass\n    @abstractmethod\n    async def QaRagAsk(self,query:str,db:Any) -> JSONResponse:\n        pass",
        "detail": "server.implementations.QaRagImpl",
        "documentation": {}
    },
    {
        "label": "EmbeddingTextModel",
        "kind": 6,
        "importPath": "server.models.QaRagServicesModels",
        "description": "server.models.QaRagServicesModels",
        "peekOfCode": "class EmbeddingTextModel(BaseModel):\n    id: UUID\n    vectorId: UUID\n    question: str\n    answer: str\n    embeddingText: str\nclass EmbeddingVectorModel(BaseModel):\n    id: UUID\n    embeddingId: UUID\n    embeddingVector: list[float]",
        "detail": "server.models.QaRagServicesModels",
        "documentation": {}
    },
    {
        "label": "EmbeddingVectorModel",
        "kind": 6,
        "importPath": "server.models.QaRagServicesModels",
        "description": "server.models.QaRagServicesModels",
        "peekOfCode": "class EmbeddingVectorModel(BaseModel):\n    id: UUID\n    embeddingId: UUID\n    embeddingVector: list[float]\nclass QaRagAskRequestModel(BaseModel):\n    query: str",
        "detail": "server.models.QaRagServicesModels",
        "documentation": {}
    },
    {
        "label": "QaRagAskRequestModel",
        "kind": 6,
        "importPath": "server.models.QaRagServicesModels",
        "description": "server.models.QaRagServicesModels",
        "peekOfCode": "class QaRagAskRequestModel(BaseModel):\n    query: str",
        "detail": "server.models.QaRagServicesModels",
        "documentation": {}
    },
    {
        "label": "PsqlDb",
        "kind": 6,
        "importPath": "server.psqldb.PsqlDb",
        "description": "server.psqldb.PsqlDb",
        "peekOfCode": "class PsqlDb:\n    def __init__(self, db_url: str):\n        self.db_url: str = db_url\n        self.pool: Any = None\n    async def connect(self) -> None:\n        async def _init(conn):\n            # enable the extension if not already\n            await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n            # register pgvector type with asyncpg\n            await register_vector(conn)",
        "detail": "server.psqldb.PsqlDb",
        "documentation": {}
    },
    {
        "label": "QaRagControllerServices",
        "kind": 6,
        "importPath": "server.services.QaRagControllerServices",
        "description": "server.services.QaRagControllerServices",
        "peekOfCode": "class QaRagControllerServices(QaRagContollerImpl):\n    async def QaRagExtract(self, db: Any) -> JSONResponse:\n        result = await qaDocService.HandleQaExtract(\"a.xlsx\")\n        embeddingTexts: list[EmbeddingTextModel] = []\n        embeddingVectors: list[EmbeddingVectorModel] = []\n        if result.questionAndAnsers is not None and result.vectors is not None:\n            for qa, vec in zip(result.questionAndAnsers, result.vectors):\n                embeddingTexts.append(\n                    EmbeddingTextModel(\n                        vectorId=qa.vectorId,",
        "detail": "server.services.QaRagControllerServices",
        "documentation": {}
    },
    {
        "label": "qaDocService",
        "kind": 5,
        "importPath": "server.services.QaRagControllerServices",
        "description": "server.services.QaRagControllerServices",
        "peekOfCode": "qaDocService = QaDocService()\nqaAiAnswers = QaAiAnswersService()\nembeddingService = EmbeddingService()\nclass QaRagControllerServices(QaRagContollerImpl):\n    async def QaRagExtract(self, db: Any) -> JSONResponse:\n        result = await qaDocService.HandleQaExtract(\"a.xlsx\")\n        embeddingTexts: list[EmbeddingTextModel] = []\n        embeddingVectors: list[EmbeddingVectorModel] = []\n        if result.questionAndAnsers is not None and result.vectors is not None:\n            for qa, vec in zip(result.questionAndAnsers, result.vectors):",
        "detail": "server.services.QaRagControllerServices",
        "documentation": {}
    },
    {
        "label": "qaAiAnswers",
        "kind": 5,
        "importPath": "server.services.QaRagControllerServices",
        "description": "server.services.QaRagControllerServices",
        "peekOfCode": "qaAiAnswers = QaAiAnswersService()\nembeddingService = EmbeddingService()\nclass QaRagControllerServices(QaRagContollerImpl):\n    async def QaRagExtract(self, db: Any) -> JSONResponse:\n        result = await qaDocService.HandleQaExtract(\"a.xlsx\")\n        embeddingTexts: list[EmbeddingTextModel] = []\n        embeddingVectors: list[EmbeddingVectorModel] = []\n        if result.questionAndAnsers is not None and result.vectors is not None:\n            for qa, vec in zip(result.questionAndAnsers, result.vectors):\n                embeddingTexts.append(",
        "detail": "server.services.QaRagControllerServices",
        "documentation": {}
    },
    {
        "label": "embeddingService",
        "kind": 5,
        "importPath": "server.services.QaRagControllerServices",
        "description": "server.services.QaRagControllerServices",
        "peekOfCode": "embeddingService = EmbeddingService()\nclass QaRagControllerServices(QaRagContollerImpl):\n    async def QaRagExtract(self, db: Any) -> JSONResponse:\n        result = await qaDocService.HandleQaExtract(\"a.xlsx\")\n        embeddingTexts: list[EmbeddingTextModel] = []\n        embeddingVectors: list[EmbeddingVectorModel] = []\n        if result.questionAndAnsers is not None and result.vectors is not None:\n            for qa, vec in zip(result.questionAndAnsers, result.vectors):\n                embeddingTexts.append(\n                    EmbeddingTextModel(",
        "detail": "server.services.QaRagControllerServices",
        "documentation": {}
    },
    {
        "label": "CustomMidlleware",
        "kind": 6,
        "importPath": "server.middleware",
        "description": "server.middleware",
        "peekOfCode": "class CustomMidlleware(BaseHTTPMiddleware):\n    async def dispatch(self, request: Request, call_next: RequestResponseEndpoint):\n        try:\n            response = await call_next(request)\n            if response.status_code == 404:\n                return JSONResponse(\n                    status_code=404,\n                    content={\"data\": \"INVALID_URL\"},\n                )\n            return response",
        "detail": "server.middleware",
        "documentation": {}
    },
    {
        "label": "extractTextWithMetadata",
        "kind": 2,
        "importPath": "utils.ExtarctTextFromFile",
        "description": "utils.ExtarctTextFromFile",
        "peekOfCode": "def extractTextWithMetadata(pdfPath: str) -> Tuple[str, List[str]]:\n    doc: Any = fitz.open(pdfPath)\n    imagesB64: List[str] = []\n    imageCounter: int = 1\n    finalTextParts: List[str] = []\n    for _, page in enumerate(doc, start=1):\n        blocks = page.get_text(\"dict\")[\"blocks\"]\n        pageItems: List[Tuple[str, float, str]] = []\n        for block in blocks:\n            if block[\"type\"] == 0:",
        "detail": "utils.ExtarctTextFromFile",
        "documentation": {}
    },
    {
        "label": "ExtractTextFromDoc",
        "kind": 2,
        "importPath": "utils.ExtarctTextFromFile",
        "description": "utils.ExtarctTextFromFile",
        "peekOfCode": "def ExtractTextFromDoc(file: str) -> Tuple[str, List[str]]:\n    textWithImages, imagesB64 = extractTextWithMetadata(file)\n    return textWithImages, imagesB64",
        "detail": "utils.ExtarctTextFromFile",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "k",
        "description": "k",
        "peekOfCode": "a = FileChunkGragService()\nasync def main():\n    response = await a.HandleChunksGraphBuildingProcess(\"opd_manual.pdf\")\n    for i in response.chunkTexts:\n        print(i.text)\n        print(i.images)\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())",
        "detail": "k",
        "documentation": {}
    },
    {
        "label": "DATABASE_CONNECTION_STRING",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DATABASE_CONNECTION_STRING = os.getenv(\"DATABASE_CONNECTION_STRING\", \"\")\npsqlDb = PsqlDb(DATABASE_CONNECTION_STRING)\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # await psqlDb.connect()\n    yield\n    # await psqlDb.close()\nserver = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "psqlDb",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "psqlDb = PsqlDb(DATABASE_CONNECTION_STRING)\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # await psqlDb.connect()\n    yield\n    # await psqlDb.close()\nserver = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "server",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "server = FastAPI(lifespan=lifespan)\nserver.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\nserver.add_middleware(CustomMidlleware)\nserver.include_router(QaRag, prefix=\"/api/v1/qa\")",
        "detail": "main",
        "documentation": {}
    }
]